{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feedback\" data-toc-modified-id=\"Feedback-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Feedback</a></span></li><li><span><a href=\"#Check-MoSeq-Versions\" data-toc-modified-id=\"Check-MoSeq-Versions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Check MoSeq Versions</a></span></li></ul></li><li><span><a href=\"#Project-setup\" data-toc-modified-id=\"Project-setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Project setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Files-and-Directory-Structure\" data-toc-modified-id=\"Files-and-Directory-Structure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Files and Directory Structure</a></span></li><li><span><a href=\"#Set-up/Restore-Progress-Variables\" data-toc-modified-id=\"Set-up/Restore-Progress-Variables-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set up/Restore Progress Variables</a></span></li><li><span><a href=\"#Generate-Configuration-Files\" data-toc-modified-id=\"Generate-Configuration-Files-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Generate Configuration Files</a></span></li><li><span><a href=\"#Download-a-Pre-trained-Flip-Classifier-Model-File\" data-toc-modified-id=\"Download-a-Pre-trained-Flip-Classifier-Model-File-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Download a Pre-trained Flip Classifier Model File</a></span></li></ul></li><li><span><a href=\"#Raw-Data-Extraction\" data-toc-modified-id=\"Raw-Data-Extraction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Raw Data Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#[OPTIONAL]-Interactive-ROI-Detection-Tool\" data-toc-modified-id=\"[OPTIONAL]-Interactive-ROI-Detection-Tool-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>[OPTIONAL] Interactive ROI Detection Tool</a></span></li><li><span><a href=\"#Extract-Session(s)\" data-toc-modified-id=\"Extract-Session(s)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract Session(s)</a></span></li><li><span><a href=\"#[OPTIONAL]-Run-Extraction-Validation-Tests\" data-toc-modified-id=\"[OPTIONAL]-Run-Extraction-Validation-Tests-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>[OPTIONAL] Run Extraction Validation Tests</a></span></li><li><span><a href=\"#[OPTIONAL]-Review-Extraction-Output\" data-toc-modified-id=\"[OPTIONAL]-Review-Extraction-Output-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>[OPTIONAL] Review Extraction Output</a></span></li><li><span><a href=\"#Aggregate-the-Extraction-Results\" data-toc-modified-id=\"Aggregate-the-Extraction-Results-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Aggregate the Extraction Results</a></span></li><li><span><a href=\"#Assign-Groups\" data-toc-modified-id=\"Assign-Groups-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Assign Groups</a></span></li><li><span><a href=\"#[OPTIONAL]-Further-Extraction-Diagnostics\" data-toc-modified-id=\"[OPTIONAL]-Further-Extraction-Diagnostics-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>[OPTIONAL] Further Extraction Diagnostics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scalar-Summary\" data-toc-modified-id=\"Scalar-Summary-3.7.1\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span>Scalar Summary</a></span></li><li><span><a href=\"#Look-up-information-using-uuid\" data-toc-modified-id=\"Look-up-information-using-uuid-3.7.2\"><span class=\"toc-item-num\">3.7.2&nbsp;&nbsp;</span>Look up information using uuid</a></span></li></ul></li></ul></li><li><span><a href=\"#Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Component-Analysis-(PCA)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Principal Component Analysis (PCA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-Principal-Component-Analysis\" data-toc-modified-id=\"Fitting-Principal-Component-Analysis-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Fitting Principal Component Analysis</a></span></li><li><span><a href=\"#Visualize-PCA-results\" data-toc-modified-id=\"Visualize-PCA-results-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Visualize PCA results</a></span></li><li><span><a href=\"#Computing-Principal-Component-Scores\" data-toc-modified-id=\"Computing-Principal-Component-Scores-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Computing Principal Component Scores</a></span></li><li><span><a href=\"#[OPTIONAL]-Compute-Model-free-Syllable-Changepoints\" data-toc-modified-id=\"[OPTIONAL]-Compute-Model-free-Syllable-Changepoints-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>[OPTIONAL] Compute Model-free Syllable Changepoints</a></span></li></ul></li><li><span><a href=\"#ARHMM-Modeling\" data-toc-modified-id=\"ARHMM-Modeling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>ARHMM Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-the-ARHMM\" data-toc-modified-id=\"Fitting-the-ARHMM-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Fitting the ARHMM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-Model-Path\" data-toc-modified-id=\"Set-Model-Path-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Set Model Path</a></span></li><li><span><a href=\"#Model-Parameters\" data-toc-modified-id=\"Model-Parameters-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Model Parameters</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Train Model</a></span></li></ul></li><li><span><a href=\"#Get-Best-Model-Fit\" data-toc-modified-id=\"Get-Best-Model-Fit-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Get Best Model Fit</a></span></li></ul></li><li><span><a href=\"#Notebook-End\" data-toc-modified-id=\"Notebook-End-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Notebook End</a></span></li><li><span><a href=\"#User-Survey\" data-toc-modified-id=\"User-Survey-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>User Survey</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1oc0_0mlN0VTZEPMQTg_hnYAC87Lb58MI\">\n",
    "\n",
    "MoSeq2 is a software toolkit for unsupervised modeling and characterization of animal behavior. Moseq takes depth recordings of animals as input and outputs a rich description of behavior as a series of kinematic motifs called 'syllables'. __The model output can be analyzed using the [MoSeq2 Analysis Visualization Notebook](./MoSeq2-Analysis-Visualization-Notebook.ipynb).__\n",
    "***\n",
    "In this notebook, the **Markdown** above each cell describes the purpose of the cell(s), cell output, and the instructions for running the cell(s) and/or interacting with the widget. The **inline code comments** in the code block provides contextual information about the function, code structure, and parameters.\n",
    "***\n",
    "\n",
    "For more information and detailed instructions, please visit our [Wiki](https://github.com/dattalab/moseq2-app/wiki).\n",
    "    \n",
    "## Feedback\n",
    "For general feedback and feature requests, please fill out [this survey](https://forms.gle/FbtEN8E382y8jF3p6).\n",
    "\n",
    "## Check MoSeq Versions\n",
    "- **Run the following cell** to check if `moseq2-app` is installed in your current environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!moseq2-extract --version\n",
    "!moseq2-pca --version\n",
    "!moseq2-model --version\n",
    "!moseq2-viz --version\n",
    "\n",
    "import sys\n",
    "import moseq2_app\n",
    "\n",
    "print('Python path:', sys.executable)\n",
    "print('MoSeq2 app version:', moseq2_app.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup\n",
    "\n",
    "## Files and Directory Structure\n",
    "\n",
    "The currently accepted depth data extensions are:\n",
    "- `.dat` (raw depth files from our kinect2 data acquisition software)\n",
    "- `.tar.gz` (compressed depth files from our kinect2 data acquisition software)\n",
    "- `.avi` (compressed depth files from the `moseq2-extract` CLI)\n",
    "\n",
    "\n",
    "**We recommend recording more than 10 hours of depth video (~1 million frames at 30 frames per second) to ensure quality MoSeq models.**\n",
    "\n",
    "Each MoSeq project is contained within a base directory. To better organize the extraction, modeling, and analysis results, you can copy the MoSeq notebooks to the base directory. At this stage, the base directory should contain **separate subfolders** for each depth recording session, as shown below:\n",
    "\n",
    "```\n",
    ".                   ** current working directory\n",
    "└── <base_dir>/     ** base directory with all depth recordings\n",
    "    ├── session_1/  ** - the folder containing all of a single session's data\n",
    "    ├   ├── depth.dat        # depth data - the recording itself\n",
    "    ├   ├── depth_ts.txt     # timestamps - csv/txt file of the frame timestamps\n",
    "    ├   └── metadata.json    # metadata - json file that contains the rodent's info (group, subjectName, etc.)\n",
    "    ...\n",
    "    ├── session_n/ **\n",
    "    ├   ├── depth.dat\n",
    "    ├   ├── depth_ts.txt\n",
    "    └── └── metadata.json\n",
    "\n",
    "```\n",
    "You can find more information about the file structure [here](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline).\n",
    "\n",
    "## Set up or Restore Progress Variables\n",
    "\n",
    "**[IMPORTANT] ALWAYS run this cell when you open this notebook.** If you don't, the analysis functions won't work.\n",
    "\n",
    "MoSeq uses a [`progress.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#progressyaml-file) file to keep track of the progress. \n",
    "\n",
    "The following cell generates a `progress.yaml` file, or loads your progress from the last saved checkpoint. \n",
    "\n",
    "- The extraction progress bar indicates the total number of extracted sessions.\n",
    "- The names of sessions that haven't been extracted is printed explicitly.\n",
    "\n",
    "**Instructions:**\n",
    "- **Specify the base directory, the folder with all the depth recordings,** in the `base_dir` field. No change is needed if the notebooks are in the base directory.\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import check_progress, restore_progress_vars\n",
    "\n",
    "base_dir = './' # Add the path to your data folder here.\n",
    "progress_filepath = join(base_dir, 'progress.yaml')\n",
    "\n",
    "progress_paths = restore_progress_vars(progress_filepath, init=True, overwrite=False)\n",
    "check_progress(progress_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Configuration Files\n",
    "\n",
    "MoSeq uses the [`config.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#configyaml-file) to hold all configurable parameters for all steps in the MoSeq pipeline. Parameters are added to this file as you progress through the notebook. The config file can be used to run an identical pipeline in future analyses.\n",
    "\n",
    "The following cell generates the `config.yaml` file for the analysis pipeline.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import generate_config_command\n",
    "\n",
    "config_filepath = join(progress_paths['base_dir'], 'config.yaml')\n",
    "\n",
    "print(f'generating file in path: {config_filepath}')\n",
    "generate_config_command(config_filepath)\n",
    "progress_paths = update_progress(progress_filepath, 'config_file', config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a Pre-trained Flip Classifier Model File\n",
    "\n",
    "MoSeq2 uses a Random Forest flip classifier to guarantee that the mouse is always pointed to the right after cropping and rotationally aligning the depth videos. The flip classifiers we provide __are trained for experiments run with C57BL/6 mice using Kinect v2 depth cameras__.\n",
    "\n",
    "If your dataset does not work with our pre-trained flip classifiers, we provide a [flip-classifier training notebook](./Flip-Classifier-Training-Notebook.ipynb) to train your own classifier. After using this notebook, add the path of your custom classifier to the `flip_classifier` field in the `config.yaml` file.\n",
    "\n",
    "The following cell downloads a pretrained flip classifier.\n",
    "\n",
    "**Instructions:**\n",
    "- **Select a classifier** that is trained on a dataset that best matches your experiment set up by changing the `selection` parameter in the `download_flip_command` function.\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_extract.gui import download_flip_command\n",
    "# selection=0 - large mice with fibers (default)\n",
    "# selection=1 - adult male C57s\n",
    "# selection=2 - mice with Inscopix cables\n",
    "download_flip_command(progress_paths['base_dir'], config_filepath, selection=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Interactive ROI Detection Tool\n",
    "\n",
    "In the extraction step, most of the parameters are related to detecting the Region of Interest (ROI), which is the region occupied by the mouse. Use this interactive tool to optimize the extraction parameters before extracting all of your data. This tool can also be used to catch possibly corrupted or inconsistent sessions, and to diagnose ROI detection/extraction errors. You can find more information in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#interactive-roi-detection-tool).\n",
    "\n",
    "Run the following cell to start the interactive widget. After running this tool, [`session-config.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#session-configyaml-file), a session-specific config file, will be generated.\n",
    "\n",
    "If the previous steps are run using the Command Line Interface, please run the [Setup or Restore Progress Variables cell](#Set-up-or-Restore-Progress-Variables) to setup/update the `progress.yaml` file to record the progress of the analysis pipeline.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to initialize the ROI Detection Tool. The cell returns a control panel to explore and configure parameters for detecting the ROI.\n",
    "- **Select a session from `Session Select` menu** to configure parameters for the session.\n",
    "- **Change the parameters and run the visualizer cell again** to see the updated extraction results.\n",
    "- **Click `Save Parameters`** to save the parameters for the selected session when the dot next to the session is green or you are satisfied with the results.\n",
    "- **Click `Save ROI`** if you are satisfied with the extraction result but the dot next to the session is red. This will mark the session green.\n",
    "- **Click `Check All Sessions`** to automatically check if the ROI extraction passed for all sessions.\n",
    "\n",
    "**Note:** if the cell seems to be running out of memory after the first use, set `compute_all_bgs` parameter to `False` to reduce the memory pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.util import update_config\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_app.main import interactive_roi_detector\n",
    "\n",
    "session_config_path = join(progress_paths['base_dir'], 'session_config.yaml')\n",
    "progress_paths = update_progress(progress_filepath, 'session_config', session_config_path)\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "\n",
    "    config_data['camera_type'] = 'auto' # 'kinect' or 'manual'\n",
    "    config_data['crop_size'] = (80, 80)\n",
    "    config_data['output_dir'] = 'proc' # the subfolder extracted data is saved to\n",
    "\n",
    "    # increase this value to include a larger ROI region, and vice versa\n",
    "    config_data['noise_tolerance'] = 30\n",
    "\n",
    "    # OPTIONAL additional parameters\n",
    "    # config_data['flip_classifier'] = './alternative-flip-classifier.pkl' # updated flip classifier path\n",
    "    # config_data['spatial_filter_size'] = [3] # spatial filtering kernel size; must be odd\n",
    "    # config_data['temporal_filter_size'] = (0,) # temporal filtering kernel size; must be odd\n",
    "\n",
    "    # Filtering out head-fixed cables?\n",
    "    # config_data['cable_filter_iters'] = 3 # number of cable filtering iterations\n",
    "    # config_data['cable_filter_size'] = (7, 7) # cable spatial filter kernel size\n",
    "\n",
    "compute_all_bgs = True # If False, only computes the first background on launch\n",
    "                \n",
    "overwrite = False # if True, will overwrite the previously saved session_config.yaml file\n",
    "\n",
    "interactive_roi_detector(progress_paths, compute_all_bgs=compute_all_bgs, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Session(s)\n",
    "The following cell uses the parameters from the [`config.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#configyaml-file) file or [`session-config.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#session-configyaml-file) to extract ROI from the depth videos and the scalar values related to the kinematics of the mouse, such as velocity, mouse width, mouse length, mouse height, mouse centroid, etc. The extracted videos are aligned with the extracted scalar values. You can find the file structure after extracting session(s) [here](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#after-extracting-the-data).\n",
    "\n",
    "This cell extracts the sessions serially.\n",
    "\n",
    "**Note:** If sessions are not listed when running the cell, ensure the `extensions` variable matches your depth files.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.util import update_config\n",
    "from moseq2_extract.gui import extract_found_sessions\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    \n",
    "    config_data['cluster_type'] = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
    "\n",
    "    ## SLURM PARAMETERS\n",
    "    # config_data['prefix'] = 'conda activate moseq2-app; ' # prefix that activates the conda environment\n",
    "    # config_data['memory'] = '16GB'\n",
    "    # config_data['wall_time'] = '3:00:00' # \n",
    "    # config_data['partition'] = 'short' # slurm partition\n",
    "    # config_data['run_cmd'] = False # if True, runs the commands via os.system(...), script must be run manually otherwise\n",
    "    # config_data['extract_out_script'] = 'extract_out.sh'\n",
    "\n",
    "# include the file extensions for the depth files you would like to search for and extract.\n",
    "extensions = ['.avi', '.dat', '.tar.gz'] # .avi, .dat, and/or `.tar.gz`\n",
    "\n",
    "# Set to False to select specific recordings to extract\n",
    "extract_all = True\n",
    "\n",
    "# Set to False to re-extract extracted recordings\n",
    "skip_extracted = True\n",
    "\n",
    "extract_found_sessions(progress_paths['base_dir'], \n",
    "                       progress_paths['config_file'], \n",
    "                       extensions, \n",
    "                       extract_all=extract_all, \n",
    "                       skip_extracted=skip_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Run Extraction Validation Tests\n",
    "\n",
    "Extraction quality can affect the model results and the validation tests can be used to identify the extracted sessions that need additional examination. To visually inspect the extraction, use the [Review Extraction Output](#[OPTIONAL]-Review-Extraction-Output) to see the extracted videos. To diagnose anomalies in scalar features, use the [Further Extraction Diagnostics](#[OPTIONAL]-Further-Extraction-Diagnostics) below to graph any desired scalar value.\n",
    "\n",
    "Once all the extractions are complete, The following cell runs data validation tests on the extracted data. The tests output warnings if there are any. You can find more information in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#run-extraction-validation-tests).\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import validate_extractions\n",
    "\n",
    "validate_extractions(progress_paths['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Review Extraction Output\n",
    "\n",
    "In addition to the extraction validation tests, visual inspection of the extracted videos can be useful to identify problems.\n",
    "\n",
    "The following cell starts the interactive widget. Use this interactive tool to review extracted output. You can find examples of a good and a bad extraction [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#examples-of-a-good-extraction-and-a-bad-extraction). **Reviewing the extraction output is optional.**\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Select a session** from the `Session` dropdown menu to preview its extraction output.\n",
    "- **Change the Playback Speed** slider to speed up or slow down the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import preview_extractions\n",
    "\n",
    "preview_extractions(progress_paths['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the Extraction Results\n",
    "The extraction results are aggregated into a folder call `aggregate_results` to better organize the necessary data for the rest of the pipeline.\n",
    "\n",
    "The following cell aggregates extraction results into one folder and generates a [`moseq2-index.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#moseq2-indexyaml-file) file to store all the session-specific information.\n",
    "\n",
    "**Instructions:**\n",
    "- **run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import aggregate_extract_results_command\n",
    "\n",
    "recording_format = '{start_time}_{session_name}_{subject_name}' # filename formats for the copied extracted data files\n",
    "\n",
    "# directory NAME to save all metadata+extracted videos to with above respective name format\n",
    "aggregate_results_dirname = 'aggregate_results/'\n",
    "\n",
    "train_data_dir = join(progress_paths['base_dir'], aggregate_results_dirname)\n",
    "update_progress(progress_filepath, 'train_data_dir', train_data_dir)\n",
    "\n",
    "# the subpath indicates to only aggregate extracted session paths with that subpath, only change if aggregating data from a different location\n",
    "index_filepath = aggregate_extract_results_command(progress_paths['base_dir'], recording_format, aggregate_results_dirname)\n",
    "progress_paths = update_progress(progress_filepath, 'index_file', index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Groups\n",
    "Sessions can be given group labels for analyses comparing different cohorts or experimental conditions and the labels will be stored in [`moseq2-index.yaml`](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#moseq2-indexyaml-file). This step requires that all your sessions have a `metadata.json` file containing a session name. You can find more information in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#assign-groups).\n",
    "\n",
    "If the previous steps are run using the Command Line Interface, please run the [Setup or Restore Progress Variables cell](#Set-up-or-Restore-Progress-Variables) to set up/update the `progress.yaml` file to record the progress of the analysis pipeline.\n",
    "\n",
    "The following cell starts the widget to assign groups and the widget will update the `moseq2-index.yaml` file.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Click the column header** to sort the column and use the filter icon to filter if needed.\n",
    "- **Click on the session** to select the session. **To select multiple sessions, click the sessions while holding down the [Ctrl]/[Command] key, or click the first and last entry while holding down the [Shift] key.**\n",
    "- **Enter the group name in the `Desired Group Name` field** and click `Set Group` to update the `group` column for the selected sessions.\n",
    "- Click the `Update Index File` button to save current group assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_group_setting\n",
    "\n",
    "interactive_group_setting(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Further Extraction Diagnostics\n",
    "### Scalar Summary\n",
    "The extraction step extracts kinematics-related scalar values. Using the following visualization tool to visualize the scalar values can help with discovering sessions where the measured mouse sizes and/or speeds are possible outliers. \n",
    "\n",
    "If outlier sessions do exist, review the extraction video using the Review Extractions tool and check for any irregularities. You may need to re-extract or discard sessions due to different forms of corruption. You can find more information in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#scalar-summary-for-further-extraction-diagnostics).\n",
    "\n",
    "The following cell starts the interactive widget that visualizes a summary of scalar values, such as average velocity, height, etc.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Hold [CTRL]/[Command] and click on the Selector rows** to select multiple scalars to plot.\n",
    "- **Hover over the data points** to display the session information.\n",
    "- - **Click on the legend items to show/hide groups** from the plot. Double click an item to show a single group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_scalar_summary\n",
    "\n",
    "viewer = interactive_scalar_summary(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up information using uuid\n",
    "If you are not able to identify the session of interest in the interactive widget above, you can look up additional information about the widget with uuid lookup. You can find more information about this tool in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#uuid-lookup).\n",
    "\n",
    "The following cell outputs additional information about the session with the target uuid.\n",
    "\n",
    "**Instructions:**\n",
    "- **Hover over the data point of interest** in the widget above to display Session Name, Subject Name, and uuid.\n",
    "- To look up the file paths associated with the data point using the uuid, **input the uuid in the `target_uuid` variable** below, partial uuid is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.util import uuid_lookup\n",
    "\n",
    "# Input full/partial uuid to lookup, eg. 40\n",
    "target_uuid = '40'\n",
    "\n",
    "# viewer.sorted_index['files'] is the uuid info dictionary\n",
    "uuid_lookup(target_uuid, viewer.sorted_index['files'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Principal Component Analysis(PCA)\n",
    "\n",
    "You can find more information in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#pca).\n",
    "\n",
    "**Note:** PCA is a resource-intensive step and in some cases, the kernel in Jupyter may die before the PCA step finishes. If you experience a dead kernel, please run the Fitting Principal Component Analysis(PCA) step and Computing Principal Component Scores step in the CLI. Please find the instructions in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/Command-Line-Interface-for-Extraction-and-Modeling#pca).\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to fit PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.util import update_config\n",
    "from moseq2_pca.gui import train_pca_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "pca_filename = 'pca' # Name of your PCA model h5 file to be saved\n",
    "pca_dirname = join(progress_paths['base_dir'], '_pca/') # Directory to save your computed PCA results\n",
    "progress_paths = update_progress(progress_filepath, 'pca_dirname', pca_dirname)\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "\n",
    "    # PCA parameters you may need to configure\n",
    "    config_data['overwrite_pca'] = False\n",
    "    config_data['gaussfilter_space'] = (1.5, 1) # Spatial filter for data (Gaussian)\n",
    "    config_data['medfilter_space'] = [0] # Median spatial filter\n",
    "    config_data['medfilter_time'] = [0] # Median temporal filter\n",
    "\n",
    "    # If dataset includes head-attached cables, set missing_data=True\n",
    "    config_data['missing_data'] = False # Set True for dataset with missing/dropped frames to reconstruct respective PCs.\n",
    "    config_data['missing_data_iters'] = 10 # Number of times to iterate over missing data during PCA\n",
    "    config_data['recon_pcs'] = 10 # Number of PCs to use for missing data reconstruction\n",
    "\n",
    "    # Dask Configuration\n",
    "    config_data['dask_port'] = '8787' # port to access Dask Dashboard\n",
    "\n",
    "    # UNCOMMENT to use SLURM\n",
    "    # config_data['cluster_type'] = 'slurm'\n",
    "    # config_data['nworkers'] = 8 # number of spawned jobs\n",
    "    # config_data['queue'] = 'short' # partition\n",
    "    # config_data['memory'] = '40GB' # amount of memory per worker\n",
    "    # config_data['cores'] = 1 # number of cores per worker\n",
    "    # config_data['wall_time'] = '01:00:00' # worker time limit\n",
    "\n",
    "    # UNCOMMENT if recordings contain occlusions (e.g. from overhead cables)\n",
    "    # config_data['missing_data'] = True\n",
    "\n",
    "# will train on data in aggregate_results/\n",
    "train_pca_command(progress_paths, pca_dirname, pca_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PCA results\n",
    "\n",
    "MoSeq ARHMM uses the principal components in the modeling step. Based on prior literature, the top 10 PCs should capture over 90% of the variance explained such that the ARHMM model works as designed. The PCA visualization can help you identify whether the quality of the PCs. You can find more information about PCA visualization interpretation in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/Analysis-Troubleshooting#possible-pca-problems).\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to visualize PCA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from IPython.display import display, Image\n",
    "images = [join(progress_paths['pca_dirname'], 'pca_components.png'), \n",
    "          join(progress_paths['pca_dirname'], 'pca_scree.png')]\n",
    "for im in images:\n",
    "    display(Image(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Principal Component Scores\n",
    "**Instructions:**\n",
    "- **Run the following cell** to compute principal component scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_pca.gui import apply_pca_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "scores_filename = 'pca_scores' # name of the scores file to compute and save\n",
    "\n",
    "scores_file = join(progress_paths['pca_dirname'], scores_filename + '.h5') # path to input PC scores file to model\n",
    "progress_paths = update_progress(progress_filepath, 'scores_path', scores_file)\n",
    "\n",
    "apply_pca_command(progress_paths, scores_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Model-free Syllable Changepoints\n",
    "Model-free syllable changepoints can be used to determine a target syllable duration for the modeling step. This step is optional if you don't plan to run [Get Best Model Fit](#Get-Best-Model-Fit). You can find more information about the model-free changepoints [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#computing-model-free-changepoints).\n",
    "\n",
    "**Note:** the parameters below are configured for C57 mouse data and have not been tested for other strains/species.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to compute model-free syllable changepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.util import update_config\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_pca.gui import compute_changepoints_command\n",
    "\n",
    "changepoints_filename = 'changepoints' # name of the changepoints images to generate\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    # Changepoint computation parameters you may want to configure\n",
    "    config_data['threshold'] = 0.5 # Peak threshold to use for changepoints\n",
    "    config_data['dims'] = 300 # Number of random projections to compare the computed principal components with\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'changepoints_path', changepoints_filename)\n",
    "compute_changepoints_command(progress_paths['train_data_dir'], progress_paths, changepoints_filename)\n",
    "\n",
    "# plot model-free change point results\n",
    "from os.path import join\n",
    "from IPython.display import display, Image\n",
    "\n",
    "changepoints_filename = 'changepoints'\n",
    "display(Image(join(progress_paths['pca_dirname'], changepoints_filename + '_dist.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARHMM Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the ARHMM\n",
    "Fitting the ARHMM typically requires adjusting the `kappa` hyperparameter to achieve a target syllable duration (higher values of `kappa` lead to longer syllable durations). The target duration can be determined using changepoints analysis or set heuristically to 0.3-0.4 seconds based on prior literature.\n",
    "\n",
    "In the code below, set `kappa` to `'scan'` to generate a bash script to run a series of models with different kappa values. You can specify minimum kappa value using `--min-kappa`(eg. 10,000), and maximum kappa value using `max-kappa` (eg. 10,000,000). The bash script will be generated in the specified model directory. You can read more about kappa scan in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/Analysis-Tips#recommended-practice-for-modeling).\n",
    "\n",
    "\n",
    "You can use the \"Get Best Model Fit\" cell to pick an optimal value. We recommend fitting for 100-200 iterations to pick `kappa`. For final model fitting, set `kappa` to the chosen value and fit for ~1000 iterations.\n",
    "\n",
    "You can find more information about ARHMM modeling in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#arhmm-modelling) and learn more about different ARHMM models we support in the [CLI wiki](https://github.com/dattalab/moseq2-app/wiki/Command-Line-Interface-for-Extraction-and-Modeling#arhmm-modeling).\n",
    "\n",
    "**Note:** if loading a model checkpoint, ensure the modeling parameters (especially the selected groups) are identical to that of the checkpoint. Otherwise, the model will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "base_model_path = 'saline-amphetamine/' # specify the folder that keeps all the models\n",
    "model_name = 'model.p' # Specify the model name\n",
    "\n",
    "session_path = join(progress_paths['base_dir'], base_model_path)\n",
    "model_path = join(session_path, model_name) # path to save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "\n",
    "Read the inline code comments for more information about the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.util import update_config\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    # model saving freqency (in interations); will create a checkpoints/ directory containing checkpointed models\n",
    "    config_data['checkpoint_freq'] = -1\n",
    "    config_data['use_checkpoint'] = False # resume training from latest saved checkpoint\n",
    "\n",
    "    config_data['npcs'] = 10  # number of PCs being used; base case should be npcs should have explained variance >= ~90% \n",
    "    config_data['max_states'] = 100 # number of maximum states the ARHMM can end up with\n",
    "\n",
    "    # use robust-ARHMM with t-distribution -> able to tolerate more noise\n",
    "    config_data['robust'] = True \n",
    "\n",
    "    # use separate transition matrix for each group\n",
    "    config_data['separate_trans'] = False\n",
    "\n",
    "    config_data['num_iter'] = 100 # number of iterations to train model\n",
    "\n",
    "    # syllable length probability distribution prior; (None, int or 'scan'); if None, kappa=nframes\n",
    "    config_data['kappa'] = None\n",
    "\n",
    "    # select specific groups to model; if False, will model all data as is in moseq2-index.yaml\n",
    "    config_data['select_groups'] = False\n",
    "\n",
    "\n",
    "    ### Advanced Modeling Parameters ###\n",
    "\n",
    "    config_data['hold_out'] = False # boolean to hold out data subset during the training process\n",
    "    config_data['nfolds'] = 2 # (if hold_out==True): number of folds to hold out during training; 1 fold per session\n",
    "    config_data['percent_split'] = 0 # (if hold_out==False): Training-validation split percentage\n",
    "\n",
    "    # if config_data['kappa'] == 'scan', optionally set bounds to scan kappa values between, in either a linear or log-scale.\n",
    "    # config_data['scan_scale'] = 'log' # or linear\n",
    "    # config_data['min_kappa'] = None\n",
    "    # config_data['max_kappa'] = None\n",
    "    # config_data['out_script'] = 'train_out.sh' # script file to save kappa-scanning learn_model() commands \n",
    "\n",
    "    # config_data['n_models'] = 15 # total number of models to spool\n",
    "\n",
    "    # scaling parameter for hierarchical dirichlet process\n",
    "    config_data['alpha'] = 5.7 # it's recommended to leave this parameter alone\n",
    "    config_data['gamma'] = 1e3 # it's recommended to leave this parameter alone\n",
    "\n",
    "    # Select platform to run models on\n",
    "    config_data['cluster_type'] = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
    "    config_data['ncpus'] = 0 # 0 means all the CPU cores will be used\n",
    "\n",
    "    ## SLURM PARAMETERS\n",
    "    # if config_data['kappa'] == 'scan' and config_data['culuster_type'] = 'slurm'\n",
    "    ## only edit these parameters if cluster_type == 'slurm'\n",
    "    # config_data['prefix'] = 'conda activate moseq2-app; ' # prefix that activates the conda environment\n",
    "    # config_data['memory'] = '16GB'\n",
    "    # config_data['wall_time'] = '3:00:00'\n",
    "    # config_data['partition'] = 'short'\n",
    "    # config_data['run_cmd'] = False # if True, runs the commands via os.system(...), script must be run manually otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from moseq2_model.gui import learn_model_command\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'model_path', model_path) # record the path to the trained model\n",
    "progress_paths = update_progress(progress_filepath, 'base_model_path', session_path) # record the path to folder that keeps trained model\n",
    "\n",
    "learn_model_command(progress_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best Model Fit\n",
    "This feature compares the trained model(s) with the principal components' changepoints and it supports two objectives for the comparison. `duration` finds the model where **the median syllable duration** best matches that of the principal components' changepoints. `jsd` finds the model where **the distribution of syllable durations** best match that of the principal components' changepoints. You can find more information in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#finding-best-model-fit).\n",
    "\n",
    "\n",
    "Once completed, if there are multiple models, this feature returns the best model from a list of models found in the `progress_paths['base_model_path']`.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to get the best model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_viz.gui import get_best_fit_model\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "output_file = join(progress_paths['plot_path'], 'model_vs_pc_changepoints')\n",
    "objective = 'duration' # objective could be either duration or jsd\n",
    "\n",
    "best_model_fit = get_best_fit_model(progress_paths, output_file, plot_all=True, objective=objective)\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'model_path', best_model_fit['best model - duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Notebook End \n",
    "\n",
    "# User Survey\n",
    "\n",
    "Please take some time to tell us your thoughts about this notebook:\n",
    "**[user feedback survey](https://forms.gle/FbtEN8E382y8jF3p6)**"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1623072349278,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.965px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
