{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Label-the-Rodent's-Orientations-Within-Frame-Ranges\" data-toc-modified-id=\"Label-the-Rodent's-Orientations-Within-Frame-Ranges-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Label the Rodent's Orientations Within Frame Ranges</a></span></li><li><span><a href=\"#Prepare-Train-Validation-Datasets\" data-toc-modified-id=\"Prepare-Train-Validation-Datasets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Train-Validation Datasets</a></span></li><li><span><a href=\"#Fit-or-Evaluate-the-Flip-Classifier-Model\" data-toc-modified-id=\"Fit-or-Evaluate-the-Flip-Classifier-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fit or Evaluate the Flip Classifier Model</a></span></li><li><span><a href=\"#Correct-Extracted-Dataset-Using-Train-Flip-Classifier-Model\" data-toc-modified-id=\"Correct-Extracted-Dataset-Using-Train-Flip-Classifier-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Correct Extracted Dataset Using Train Flip Classifier Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Apply-a-flip-classifier-to-correct-the-extracted-dataset\" data-toc-modified-id=\"Apply-a-flip-classifier-to-correct-the-extracted-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Apply a flip classifier to correct the extracted dataset</a></span></li><li><span><a href=\"#Preview-Corrected-Sessions\" data-toc-modified-id=\"Preview-Corrected-Sessions-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Preview Corrected Sessions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip classifiers are RandomForestClassifier models that MoSeq2-Extract uses to ensure that the mouse is always extracted with the mouse's nose pointing to the right and tail to the left. This notebook is a streamlined utility and guide for preparing data and training a model that handles your specific data acquisition use case.\n",
    "\n",
    "To use this notebook, you must first extract some data using MoSeq2-Extract to use as training data for the flip classifier model. 100K frames are optimal for training the flip classifier. \n",
    "\n",
    "This can be an iterative process if your data contains large amounts of flips throughout the extractions. On your first iteration, it is acceptable to extract the data without a flip-classifier. After training a new flip classifier, you may apply it to your dataset to correct the flips without having to re-extract the data before going into the PCA step.\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1cOwyen2Siy-_wJ1HcE0PmMUi3Lcgcwwa\"></center>\n",
    "\n",
    "## Label the Rodent's Orientations Within Frame Ranges\n",
    "Use this interactive tool to build your training dataset for the flip classifier model. Select a range of frames and identify whether the rodent is facing left or facing right. The ranges of frames are used to build your training set.\n",
    "\n",
    "**Instructions**\n",
    "- **Specify the data folder** in the `input_dir` field.\n",
    "- **Specify the path for the resulting model** in the `model_path` field. For example, `./flip-classifier-azure-ephys.pkl`.\n",
    "- **Specify the maximum number of frames to use** in the `max_frames` field, the default value is 1e5.\n",
    "- **Specify the number of tail filter iterations** in the `tail_filter_iters` field, the default value is 1.\n",
    "- **Specify the size of the spatial median blur filter kernel size** in the `space_filter_size` field, the default value is 3.is 3.\n",
    "- **Run the following cell** to set the parameters and initialize the Data Labeller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import flip_classifier_tool\n",
    "from moseq2_extract.util import read_yaml, get_strels\n",
    "\n",
    "input_dir = './' # Specify the data folder\n",
    "config_path = './config.yaml' # Specify the config file\n",
    "model_path = './flip-classifier-xx-1.pkl' ## e.g. ./flip-classifier-azure-ephys.pkl\n",
    "\n",
    "max_frames = 1e5 # max number of frames to use (performance anecdotally saturates around 1e5)\n",
    "\n",
    "config_data = read_yaml(config_path) # load config data\n",
    "\n",
    "strels = get_strels(config_data)# get structuring elements\n",
    "\n",
    "clean_parameters = {'prefilter_space': config_data['spatial_filter_size'], # median filter kernel sizes \n",
    "                    'prefilter_time': config_data['temporal_filter_size'], # temporal filter kernel sizes\n",
    "                    'strel_tail': strels['strel_tail'], # struc. element for filtering tail\n",
    "                    'iters_tail': config_data['tail_filter_iters'], # number of iters for morph. opening to filter tail\n",
    "                    'frame_dtype': config_data['frame_dtype'], # frame dtype\n",
    "                    'strel_min':strels['strel_min'], # structuring element for erosion\n",
    "                    'iters_min': config_data['cable_filter_iters']}# number of iterations for erosion\n",
    "\n",
    "continuous_slider_update = True # update the view as the slider values are updated\n",
    "launch_gui = True # launches the frame selector gui\n",
    "\n",
    "FF = flip_classifier_tool(input_dir=input_dir,\n",
    "                          output_file=model_path,\n",
    "                          max_frames=max_frames,\n",
    "                          clean_parameters=clean_parameters,\n",
    "                          continuous_slider_update=continuous_slider_update,\n",
    "                          launch_gui=launch_gui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "- **Run the following cell** to launch the Data Labeller GUI.\n",
    "- **Select the target session from the dropdown menu** and start labeling.\n",
    "- **Drag the slider** to select a frame index to preview.\n",
    "- **Click `Start Range`** to starting selecting the range. **Drag the slider** to the end of the range. **Click `Facing Left` or `Facing Right`** to specify the correct orientation for the range of frames. After specifying the orientation, the selected frames will be added to the dataset used to train the model.\n",
    "- **Click `Cancel Select`** to cancel the selection.\n",
    "\n",
    "**Note**: The `Current Total Selected` section turns green when there are enough labeled frames to train the model. If your frame selection was interrupted for any reason, and you would like to relaunch the tool with all of your previously selected frame ranges, uncomment the code in the following cell and run the cell.\n",
    "\n",
    "If two frame ranges are selected with overlapping frames, the training set will only include the unique selected indices, removing duplicates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF.interactive_launch_frame_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train-Validation Datasets\n",
    "This cell splits your dataset into train/validation sets and displays images in the datasets.\n",
    "\n",
    "Upon completion, the cell will plot a 2x2 grid. The left column contains the correctly flipped examples of the data. The right column contains the incorrect examples. The bottom row contains the y-axis flip versions of the top row.\n",
    "\n",
    "Ensure that only the plotted frames in the __left__ column show the rodent is pointed to the right.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to split your dataset into train/validation sets to train the flip classifier.\n",
    "- **Specify the percentage for train/validation split** in `test_size`, and the default value is 20, meaning 20\\% of the data is used as the validation dataset.\n",
    "- If you want to preview the training dataset, **set `plot_examples` to `True`.** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 20 # percent train/validation split\n",
    "plot_examples = False # Set plot_examples to True to display the training data.\n",
    "\n",
    "FF.prepare_datasets(test_size, plot_examples=plot_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit or Evaluate the Flip Classifier Model\n",
    "\n",
    "The following cell train a random forest classifier model with the data, determine the flip classifier's accuracy and then save the model to your desired output path.\n",
    "\n",
    "**Instructions:**\n",
    "- **Specify the maximum depth of the tree**.  Increase this value if your data includes larger amounts of variability and you want to increase model complexity. Variability can arise from obstructions, different rodent sizes, larger crop sizes, etc. **Please be mindful of over-fitting**.\n",
    "- **Specify the number of parallel jobs** to run `fit()` and `predict()`.\n",
    "- **Set the `train` variable to `True`** if you want to train a new model with the selected data, otherwise, it will only evaluate the model on the selected data.\n",
    "- **Run the following cell** to fit or evaluate the flip classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6 \n",
    "         \n",
    "n_jobs = 4\n",
    "verbose = 0 # levels of verbosity: [0, 1, 2]\n",
    "train = True\n",
    "\n",
    "FF.train_and_evaluate_model(n_jobs=n_jobs,\n",
    "                            max_depth=max_depth,\n",
    "                            verbose=verbose,\n",
    "                            train=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Extracted Dataset Using Train Flip Classifier Model\n",
    "\n",
    "Use a pre-trained flip classifier model to correct extractions in your dataset that may have frames where the rodent is incorrectly flipped. \n",
    "### Apply a flip classifier to correct the extracted dataset\n",
    "**Instructions:**\n",
    "- **Set the `write_movie` variable to `True`** if you want to write a new video with the corrected frames.\n",
    "- **Set the `verbose` variable to `True`** if you want to display progress bars for each session.\n",
    "- **Run this cell** to apply the trained model to correct the extracted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 4000\n",
    "frame_path = 'frames'\n",
    "write_movie = True\n",
    "verbose = False\n",
    "\n",
    "FF.apply_flip_classifier(chunk_size=chunk_size,\n",
    "                         frame_path=frame_path,\n",
    "                         write_movie=write_movie,\n",
    "                         verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Corrected Sessions\n",
    "**Instructions:**\n",
    "- **Run the following cell** to preview corrected sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import preview_extractions\n",
    "\n",
    "preview_extractions(input_dir, flipped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
