{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feedback\" data-toc-modified-id=\"Feedback-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Feedback</a></span></li><li><span><a href=\"#Check-MoSeq-Versions\" data-toc-modified-id=\"Check-MoSeq-Versions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Check MoSeq Versions</a></span></li></ul></li><li><span><a href=\"#Project-setup\" data-toc-modified-id=\"Project-setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Project setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Files-and-Directory-Structure\" data-toc-modified-id=\"Files-and-Directory-Structure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Files and Directory Structure</a></span></li><li><span><a href=\"#Setup/Restore-Progress-Variables\" data-toc-modified-id=\"Setup/Restore-Progress-Variables-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup/Restore Progress Variables</a></span></li><li><span><a href=\"#Generate-Configuration-Files\" data-toc-modified-id=\"Generate-Configuration-Files-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Generate Configuration Files</a></span></li><li><span><a href=\"#Download-a-Pre-trained-Flip-Classifier-Model-File\" data-toc-modified-id=\"Download-a-Pre-trained-Flip-Classifier-Model-File-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Download a Pre-trained Flip Classifier Model File</a></span></li></ul></li><li><span><a href=\"#Raw-Data-Extraction\" data-toc-modified-id=\"Raw-Data-Extraction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Raw Data Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#[OPTIONAL]-Interactive-ROI-Detection-Tool\" data-toc-modified-id=\"[OPTIONAL]-Interactive-ROI-Detection-Tool-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>[OPTIONAL] Interactive ROI Detection Tool</a></span></li><li><span><a href=\"#Extract-Session(s)\" data-toc-modified-id=\"Extract-Session(s)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract Session(s)</a></span></li><li><span><a href=\"#[OPTIONAL]-Run-Extraction-Validation-Tests\" data-toc-modified-id=\"[OPTIONAL]-Run-Extraction-Validation-Tests-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>[OPTIONAL] Run Extraction Validation Tests</a></span><ul class=\"toc-item\"><li><span><a href=\"#[OPTIONAL]-Review-Extraction-Output\" data-toc-modified-id=\"[OPTIONAL]-Review-Extraction-Output-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>[OPTIONAL] Review Extraction Output</a></span></li></ul></li><li><span><a href=\"#Aggregate-the-Extraction-Results\" data-toc-modified-id=\"Aggregate-the-Extraction-Results-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Aggregate the Extraction Results</a></span></li><li><span><a href=\"#Assign-Groups\" data-toc-modified-id=\"Assign-Groups-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Assign Groups</a></span></li><li><span><a href=\"#[OPTIONAL]-Further-Extraction-Diagnostics\" data-toc-modified-id=\"[OPTIONAL]-Further-Extraction-Diagnostics-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>[OPTIONAL] Further Extraction Diagnostics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Look-up-information-using-uuid\" data-toc-modified-id=\"Look-up-information-using-uuid-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Look up information using uuid</a></span></li></ul></li></ul></li><li><span><a href=\"#Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Component-Analysis-(PCA)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Principal Component Analysis (PCA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-Principal-Component-Analysis\" data-toc-modified-id=\"Fitting-Principal-Component-Analysis-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Fitting Principal Component Analysis</a></span></li><li><span><a href=\"#Visualize-PCA-results\" data-toc-modified-id=\"Visualize-PCA-results-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Visualize PCA results</a></span></li><li><span><a href=\"#Computing-Principal-Component-Scores\" data-toc-modified-id=\"Computing-Principal-Component-Scores-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Computing Principal Component Scores</a></span></li><li><span><a href=\"#[OPTIONAL]-Compute-Model-free-Syllable-Changepoints\" data-toc-modified-id=\"[OPTIONAL]-Compute-Model-free-Syllable-Changepoints-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>[OPTIONAL] Compute Model-free Syllable Changepoints</a></span></li></ul></li><li><span><a href=\"#ARHMM-Modeling\" data-toc-modified-id=\"ARHMM-Modeling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>ARHMM Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-the-ARHMM\" data-toc-modified-id=\"Fitting-the-ARHMM-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Fitting the ARHMM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-Model-Path\" data-toc-modified-id=\"Set-Model-Path-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Set Model Path</a></span></li><li><span><a href=\"#General-Parameters\" data-toc-modified-id=\"General-Parameters-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>General Parameters</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Train Model</a></span></li></ul></li><li><span><a href=\"#Get-Best-Model-Fit\" data-toc-modified-id=\"Get-Best-Model-Fit-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Get Best Model Fit</a></span></li></ul></li><li><span><a href=\"#Notebook-End\" data-toc-modified-id=\"Notebook-End-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Notebook End</a></span></li><li><span><a href=\"#User-Survey\" data-toc-modified-id=\"User-Survey-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>User Survey</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1oc0_0mlN0VTZEPMQTg_hnYAC87Lb58MI\">\n",
    "\n",
    "MoSeq2 is a software toolkit for unsupervised modeling and characterization of animal behavior. Moseq takes depth recordings of animals as input and outputs a rich description of behavior as a series of kinematic motifs called 'syllables'. __The model output can be analyzed using the [Interactive Results Exploration](./Interactive-Model-Results-Exploration.ipynb) notebook.__\n",
    "\n",
    "For more information and detailed instruction, please visit our [Wiki](https://github.com/dattalab/moseq2-app/wiki).\n",
    "    \n",
    "## Feedback\n",
    "For general feedback and feature requests, please fill out [this survey](https://forms.gle/FbtEN8E382y8jF3p6).\n",
    "\n",
    "## Check MoSeq Versions\n",
    "- **Run the following cell** to check if `moseq2-app` is installed in your current environment. <!--- The latest working version number is `0.2.2`. We should update the version number for all the repos and list them here. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!moseq2-extract --version\n",
    "!moseq2-pca --version\n",
    "!moseq2-model --version\n",
    "!moseq2-viz --version\n",
    "\n",
    "import sys\n",
    "import moseq2_app\n",
    "\n",
    "print('Python path:', sys.executable)\n",
    "print('MoSeq2 app version:', moseq2_app.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup\n",
    "\n",
    "## Files and Directory Structure\n",
    "\n",
    "The currently accepted depth data extensions are:\n",
    "- `.dat` (raw depth files from our kinect2 data acquisition software)\n",
    "- `.tar.gz` (compressed depth files from our kinect2 data acquisition software)\n",
    "- `.avi` (compressed depth files from the `moseq2-extract` command line interface)\n",
    "- `.mkv` (generated from Microsoft's recording software for the Azure Kinect)\n",
    "\n",
    "\n",
    "**We recommend recording more than 10 hours of depth video (~1 million frames at 30 frames per second) to ensure quality MoSeq models**\n",
    "\n",
    "Each MoSeq project is contained within a base directory. To better organize the extraction, modeling and analysis results, you can copy the MoSeq notebooks to the base directory. At this stage, the base directory should contain **separate subfolders** for each depth recording session, as shown below:\n",
    "\n",
    "```\n",
    ".                   ** current working directory\n",
    "└── <base_dir>/     ** base directory with all depth recordings\n",
    "    ├── session_1/  ** - the folder containing all of a single session's data\n",
    "    ├   ├── depth.dat        # depth data - the recording itself\n",
    "    ├   ├── depth_ts.txt     # timestamps - csv/txt file of the frame timestamps\n",
    "    ├   └── metadata.json    # metadata - json file that contains the rodent's info (group, subjectName, etc.)\n",
    "    ...\n",
    "    ├── session_n/ **\n",
    "    ├   ├── depth.dat\n",
    "    ├   ├── depth_ts.txt\n",
    "    └── └── metadata.json\n",
    "\n",
    "```\n",
    "\n",
    "__Note: if your data was acquired using an Azure Kinect, you will not have `depth_ts.txt` or `metadata.json` in your session subfolders. MoSeq will automatically generate the necessary files.__ The directory structure would be the following:\n",
    "```\n",
    ".\n",
    "└── Data_Directory/\n",
    "    ├── session_1/ ** - the folder containing all of a single session's data\n",
    "    ├   └── session_1.mkv    # depth data - the recording itself\n",
    "    ...\n",
    "    ├── session_n/ **\n",
    "    └── └── session_n.mkv\n",
    "    \n",
    "```\n",
    "\n",
    "## Setup/Restore Progress Variables\n",
    "\n",
    "MoSeq uses a `progress.yaml` file to keep track of the progress. Use the following cell to generate a `progress.yaml` file, or to load your progress from the last saved checkpoint.\n",
    "- The extraction progress bar indicates the total number of extracted sessions.\n",
    "-The names of sessions that haven't been extracted is printed explicitly.\n",
    "\n",
    "**Instructions:**\n",
    "- **Specify the base directory** in the `base_dir` field.\n",
    "- **Run the following cell** to setup/restore progress variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import check_progress, restore_progress_vars\n",
    "\n",
    "base_dir = './' # Add the path to your data folder here.\n",
    "progress_filepath = join(base_dir, 'progress.yaml')\n",
    "\n",
    "progress_paths = restore_progress_vars(progress_filepath, init=True, overwrite=False)\n",
    "check_progress(progress_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Configuration Files\n",
    "\n",
    "The `config.yaml` file is used to hold all configurable parameters for all steps in the MoSeq pipeline. Parameters are added to this file as you progress through the notebook. The config file can be used to run an identical pipeline in future analyses.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to generate the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import generate_config_command\n",
    "\n",
    "config_filepath = join(progress_paths['base_dir'], 'config.yaml')\n",
    "\n",
    "print(f'generating file in path: {config_filepath}')\n",
    "generate_config_command(config_filepath)\n",
    "progress_paths = update_progress(progress_filepath, 'config_file', config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a Pre-trained Flip Classifier Model File\n",
    "\n",
    "MoSeq2 uses a Random Forest flip classifier to guarantee that the mouse is always pointed to the right after cropping and rotationally aligning the depth videos. The flip classifiers we provide __are trained for experiments run with C57BL/6 mice using Kinect v2 depth cameras__.\n",
    "\n",
    "If your dataset does not work with our pre-trained flip classifiers, we provide a [flip-classifier training notebook](https://github.com/dattalab/moseq2-app/)<!--- This link should be updated once Dev gets merged into release -->. After using this notebook, add the path of your custom classifier to the `flip_classifier` field in the `config.yaml` file.\n",
    "\n",
    "**Instructions:**\n",
    "- **Select a mouse type** for the flip classifier.\n",
    "- **Run the following cell** to download the pre-trained flip classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_extract.gui import download_flip_command\n",
    "# selection=0 - large mice with fibers (default)\n",
    "# selection=1 - adult male C57s\n",
    "# selection=2 - mice with Inscopix cables\n",
    "download_flip_command(progress_paths['base_dir'], config_filepath, selection=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Interactive ROI Detection Tool\n",
    "\n",
    "Use this interactive tool to optimize the extraction parameters prior to extracting all of your data. Most of the parameters are related to detecting the Region of Interest (ROI), which is the region occupied by the mouse. This tool can also be used to catch possibly corrupted or inconsistent sessions, and to diagnose ROI detection/extraction errors.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to initialize the ROI Detection Tool. The cell returns a control panel to explore and configure parameters for detecting the ROI.\n",
    "- **Select a session from `Session Select` menu** to configure parameters for the session.\n",
    "- **Change the parameters and run the visualizer cell again** to see the updated extraction results.\n",
    "- **Click `Save Parameters`** to save the parameters for the selected session when the dot next to the session is green or you are satisfied with the results.\n",
    "- **Click `Save ROI`** if you are satisfied with the extraction result but the dot next to the session is red. This will mark the session green.\n",
    "- **Click `Check All Sessions`** to automatically check if the ROI extraction passed for all sessions.\n",
    "\n",
    "**Note:** if cell seems to be running out of memory after first use, uncheck `compute_all_bgs` box to reduce the memory pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import ruamel.yaml as yaml\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_app.main import interactive_roi_detector\n",
    "\n",
    "session_config_path = join(progress_paths['base_dir'], 'session_config.yaml')\n",
    "progress_paths = update_progress(progress_filepath, 'session_config', session_config_path)\n",
    "\n",
    "with open(progress_paths['config_file'], 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "config_data['camera_type'] = 'auto' # 'kinect', 'azure', or 'manual'\n",
    "config_data['crop_size'] = (80, 80)\n",
    "config_data['output_dir'] = 'proc' # the subfolder extracted data is saved to\n",
    "\n",
    "# increase this value to include a larger ROI region, and vice versa\n",
    "config_data['noise_tolerance'] = 30\n",
    "\n",
    "# OPTIONAL additional parameters\n",
    "# config_data['flip_classifier'] = './alternative-flip-classifier.pkl' # updated flip classifier path\n",
    "# config_data['spatial_filter_size'] = [3] # spatial filtering kernel size; must be odd\n",
    "# config_data['temporal_filter_size'] = (0,) # temporal filtering kernel size; must be odd\n",
    "\n",
    "# Filtering out head-fixed cables?\n",
    "# config_data['cable_filter_iters'] = 3 # number of cable filtering iterations\n",
    "# config_data['cable_filter_size'] = (7, 7) # cable spatial filter kernel size\n",
    "\n",
    "with open(progress_paths['config_file'], 'w') as f:\n",
    "    yaml.safe_dump(config_data, f)\n",
    "\n",
    "compute_all_bgs = True # If False, only computes the first background on launch\n",
    "                \n",
    "overwrite = False # if True, will overwrite the previously saved session_config.yaml file\n",
    "\n",
    "interactive_roi_detector(progress_paths, compute_all_bgs=compute_all_bgs, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Session(s)\n",
    "The following cell uses the parameters from `config.yaml` file or the above interactive tool to extract ROI from the depth videos and the scalar values related to the kinematics of the mouse, such as velocity, mouse width, mouse length, mouse height, mouse centroid, etc. The extracted videos are aligned with the extracted scalar values. \n",
    "\n",
    "**Note:** If sessions are not listed when running the cell, ensure the `extensions` variable matches your depth files.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Specify the file extension(s)** in `extensions` variable, such as `.avi`, `.dat`, `.mkv`, `.tar.gz`.\n",
    "- **Run the following cell** to extract sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import ruamel.yaml as yaml\n",
    "from moseq2_extract.gui import extract_found_sessions\n",
    "\n",
    "with open(progress_paths['config_file'], 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "    \n",
    "config_data['cluster_type'] = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
    "\n",
    "## SLURM PARAMETERS\n",
    "# config_data['prefix'] = 'conda activate moseq2-app; ' # prefix that activates the conda environment\n",
    "# config_data['memory'] = '16GB'\n",
    "# config_data['wall_time'] = '3:00:00' # \n",
    "# config_data['partition'] = 'short' # slurm partition\n",
    "# config_data['run_cmd'] = False # if True, runs the commands via os.system(...), script must be run manually otherwise\n",
    "# config_data['extract_out_script'] = 'extract_out.sh'\n",
    "          \n",
    "with open(progress_paths['config_file'], 'w') as f:\n",
    "    yaml.safe_dump(config_data, f)\n",
    "\n",
    "# include the file extensions for the depth files you would like to search for and extract.\n",
    "extensions = ['.avi', '.dat'] # .avi, .dat, and/or .mkv\n",
    "\n",
    "# Set to False to select specific recordings to extract\n",
    "extract_all = True\n",
    "\n",
    "# Set to False to re-extract extracted recordings\n",
    "skip_extracted = True\n",
    "\n",
    "extract_found_sessions(progress_paths['base_dir'], \n",
    "                       progress_paths['config_file'], \n",
    "                       extensions, \n",
    "                       extract_all=extract_all, \n",
    "                       skip_extracted=skip_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Run Extraction Validation Tests\n",
    "\n",
    "Once all the extractions are complete, use the following cell to run data validation tests. The tests can output either an error or a warning. \n",
    "- An __error__ indicates that the session is corrupted in some way and should be excluded from PCA and Modeling.\n",
    "- A __warning__ indicates that one or more sessions are statistical outliers.\n",
    "  - A warning can indicate that the session may need to be inspected prior to continuing into the PCA step. \n",
    "  - Warnings can be ignored when they are consistent with experimental design (e.g. abnormally high velocity in an animal that received a stimulant drug). \n",
    "\n",
    "To diagnose anomalies in scalar features, use the [Further Extraction Diagnostics](#[OPTIONAL]-Further-Extraction-Diagnostics) below to graph any desired scalar value.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to validate extraction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import validate_extractions\n",
    "\n",
    "validate_extractions(progress_paths['base_dir']) # path to pre-existing aggregate_results/ folder is also permissible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Review Extraction Output\n",
    "\n",
    "Use this interactive tool to review extracted output. **Reviewing the extraction output is optional.**\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** initialize the Review Extraction Tool.\n",
    "- **Select a session** from the `Session` dropdown menu to preview its extraction output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import preview_extractions\n",
    "\n",
    "preview_extractions(progress_paths['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the Extraction Results\n",
    "**Instructions:**\n",
    "- **run the following cell** to aggregate all the extracted results into one folder for the rest of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import aggregate_extract_results_command\n",
    "\n",
    "recording_format = '{start_time}_{session_name}_{subject_name}' # filename formats for the copied extracted data files\n",
    "\n",
    "# directory NAME to save all metadata+extracted videos to with above respective name format\n",
    "aggregate_results_dirname = 'aggregate_results/'\n",
    "\n",
    "train_data_dir = join(progress_paths['base_dir'], aggregate_results_dirname)\n",
    "update_progress(progress_filepath, 'train_data_dir', train_data_dir)\n",
    "\n",
    "# the subpath indicates to only aggregate extracted session paths with that subpath, only change if aggregating data from a different location\n",
    "index_filepath = aggregate_extract_results_command(progress_paths['base_dir'], recording_format, aggregate_results_dirname)\n",
    "progress_paths = update_progress(progress_filepath, 'index_file', index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Groups\n",
    "Sessions can be given group labels for analyses comparing different cohorts or experimental conditions and the labels will be stored in `moseq2-index.yaml`. This step requires that all your sessions have a `metadata.json` file containing a session name.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to display the data table for group assigning.\n",
    "- **Click the column header** to sort the column and use the filter icon to filter if needed.\n",
    "- **Click on the session** to select the session. **To select multiple sessions, click the sessions while holding down the [Ctrl]/[Command] key, or click the first and last entry while holding down the [Shift] key.**\n",
    "\n",
    "- **Enter the group name in the `Desired Group Name` field** and click `Set Group` to update the `group` column for the selected sessions.\n",
    "- Click the `Update Index File` button to save current group assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_group_setting\n",
    "\n",
    "interactive_group_setting(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Further Extraction Diagnostics\n",
    "\n",
    "The extraction step extracts kinematics-related scalar values. Using the following visualization tool to visualize the scalar values can help with discovering sessions where the measured mouse sizes and/or speeds are possible outliers. If outlier sessions do exist, review the extraction video using the Review Extractions tool and check for any irregularities. You may need to re-extract or discard sessions due to different forms of corruption.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to visualize a summary of scalar values, such as average velocity, height, etc.\n",
    "- **Hold [CTRL]/[Command] and click on the Selector rows** to select multiple scalars to plot.\n",
    "- **Hover over the data points** to display the session information.\n",
    "- - **Click on the legend items to show/hide groups** from the plot. Double click an item to show a single group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_scalar_summary\n",
    "\n",
    "viwer = interactive_scalar_summary(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up information using uuid\n",
    "**Instructions:**\n",
    "- **Hover over the data point of interest** to display Session Name, Subject Name and uuid.\n",
    "- To look up the file paths associated with the data point using the uuid, **input the uuid in the `target_uuid` variable** below, partial uuid is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.util import uuid_lookup\n",
    "\n",
    "# Input full/partial uuid to lookup, eg. 40\n",
    "target_uuid = '40'\n",
    "\n",
    "# viewer.sorted_index['files'] is the uuid info dictionary\n",
    "uuid_lookup(target_uuid, viewer.sorted_index['files'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Principal Component Analysis\n",
    "**Instructions:**\n",
    "- **Run the following cell** to fit PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import ruamel.yaml as yaml\n",
    "from moseq2_pca.gui import train_pca_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "pca_filename = 'pca' # Name of your PCA model h5 file to be saved\n",
    "pca_dirname = join(progress_paths['base_dir'], '_pca/') # Directory to save your computed PCA results\n",
    "\n",
    "with open(progress_paths['config_file'], 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "# PCA parameters you may need to configure\n",
    "config_data['overwrite_pca'] = False\n",
    "config_data['gaussfilter_space'] = (1.5, 1) # Spatial filter for data (Gaussian)\n",
    "config_data['medfilter_space'] = [0] # Median spatial filter\n",
    "config_data['medfilter_time'] = [0] # Median temporal filter\n",
    "\n",
    "# If dataset includes head-attached cables, set missing_data=True\n",
    "config_data['missing_data'] = False # Set True for dataset with missing/dropped frames to reconstruct respective PCs.\n",
    "config_data['missing_data_iters'] = 10 # Number of times to iterate over missing data during PCA\n",
    "config_data['recon_pcs'] = 10 # Number of PCs to use for missing data reconstruction\n",
    "\n",
    "# Dask Configuration\n",
    "config_data['dask_port'] = '8787' # port to access Dask Dashboard\n",
    "\n",
    "# UNCOMMENT to use SLURM\n",
    "# config_data['cluster_type'] = 'slurm'\n",
    "# config_data['nworkers'] = 8 # number of spawned jobs\n",
    "# config_data['queue'] = 'short' # partition\n",
    "# config_data['memory'] = '40GB' # amount of memory per worker\n",
    "# config_data['cores'] = 1 # number of cores per worker\n",
    "# config_data['wall_time'] = '01:00:00' # worker time limit\n",
    "\n",
    "# UNCOMMENT if recordings contain occlusions (e.g. from overhead cables)\n",
    "# config_data['missing_data'] = True\n",
    "\n",
    "with open(progress_paths['config_file'], 'w') as f:\n",
    "    yaml.safe_dump(config_data, f)\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'pca_dirname', pca_dirname)\n",
    "\n",
    "# will train on data in aggregate_results/\n",
    "train_pca_command(progress_paths, pca_dirname, pca_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PCA results\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to visualize PCA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from IPython.display import display, Image\n",
    "images = [join(progress_paths['pca_dirname'], 'pca_components.png'), \n",
    "          join(progress_paths['pca_dirname'], 'pca_scree.png')]\n",
    "for im in images:\n",
    "    display(Image(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Principal Component Scores\n",
    "**Instructions:**\n",
    "- **Run the following cell** to compute principal component scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_pca.gui import apply_pca_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "scores_filename = 'pca_scores' # name of the scores file to compute and save\n",
    "\n",
    "scores_file = join(progress_paths['pca_dirname'], scores_filename + '.h5') # path to input PC scores file to model\n",
    "progress_paths = update_progress(progress_filepath, 'scores_path', scores_file)\n",
    "\n",
    "apply_pca_command(progress_paths, scores_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Compute Model-free Syllable Changepoints\n",
    "Model-free syllable changepoints can be used to determine a target syllable duration for the modeling step.\n",
    "**Note:** the parameters below are configured for C57 mouse data and have not been tested for other strains/species.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to compute model-free syllable changepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml as yaml\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_pca.gui import compute_changepoints_command\n",
    "\n",
    "with open(progress_paths['config_file'], 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "changepoints_filename = 'changepoints' # name of the changepoints images to generate\n",
    "\n",
    "# Changepoint computation parameters you may want to configure\n",
    "config_data['threshold'] = 0.5 # Peak threshold to use for changepoints\n",
    "config_data['dims'] = 300 # Number of random projections to compare the computed principal components with\n",
    "\n",
    "with open(progress_paths['config_file'], 'w') as f:\n",
    "    yaml.safe_dump(config_data, f)\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'changepoints_path', changepoints_filename)\n",
    "compute_changepoints_command(progress_paths['train_data_dir'], progress_paths, changepoints_filename)\n",
    "\n",
    "# plot model-free change point results\n",
    "from os.path import join\n",
    "from IPython.display import display, Image\n",
    "\n",
    "changepoints_filename = 'changepoints'\n",
    "display(Image(join(progress_paths['pca_dirname'], changepoints_filename + '_dist.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARHMM Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the ARHMM\n",
    "Fitting the ARHMM typically requires adjusting the `kappa` hyperparameter to achieve a target syllable duration (higher values of `kappa` lead to longer syllable durations). The target duration can be determined using changepoints analysis or set heuristically to 0.3-0.4 seconds based on prior literature. \n",
    "\n",
    "In the code below, set `kappa` to `'scan'` to run a family of models with different `kappa` values and use the \"Get Best Model Fit\" cell to pick an optimal value. We recommend fitting for 100-200 iterations to pick `kappa`. For final model fitting, set `kappa` to the chosen value and fit for ~1000 iterations. \n",
    "\n",
    "**Note:** if loading a model checkpoint, ensure the modeling parameters (especially the selected groups) are identical to that of the checkpoint. Otherwise, the model will fail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "modeling_session_path = 'saline-amphetamine/' # specify the session folder the model runs on\n",
    "model_name = 'model.p' # Specify the model name\n",
    "\n",
    "session_path = join(progress_paths['base_dir'], modeling_session_path)\n",
    "model_path = join(session_path, model_name) # path to save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving freqency (in interations); will create a checkpoints/ directory containing checkpointed models\n",
    "checkpoint_freq = -1\n",
    "use_checkpoint = False # resume training from latest saved checkpoint\n",
    "\n",
    "npcs = 10  # number of PCs being used; base case should be npcs should have explained variance >= ~90% \n",
    "max_states = 100 # number of maximum states the ARHMM can end up with\n",
    "\n",
    "# use robust-ARHMM with t-distribution -> able to tolerate more noise\n",
    "robust = True \n",
    "\n",
    "# separate group transition graphs; set to True if you want to compare multiple groups\n",
    "separate_trans = True \n",
    "\n",
    "num_iter = 100 # number of iterations to train model\n",
    "\n",
    "# syllable length probability distribution prior; (None, int or 'scan'); if None, kappa=nframes\n",
    "kappa = None \n",
    "\n",
    "select_groups = False # select specific groups to model; if False, will model all data as is in moseq2-index.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moseq2_model.gui import learn_model_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "### Advanced Modeling Parameters ###\n",
    "\n",
    "hold_out = False # boolean to hold out data subset during the training process\n",
    "nfolds = 2 # (if hold_out==True): number of folds to hold out during training; 1 fold per session\n",
    "\n",
    "# if kappa == 'scan', optionally set bounds to scan kappa values between, in either a linear or log-scale.\n",
    "scan_scale = 'log' # or linear\n",
    "min_kappa = None\n",
    "max_kappa = None\n",
    "out_script = 'train_out.sh' # script file to save kappa-scanning learn_model() commands \n",
    "\n",
    "# total number of models to spool\n",
    "n_models = 15\n",
    "\n",
    "# Select platform to run models on\n",
    "cluster_type = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
    "run_cmd = False # if True, runs the commands via os.system(...), script must be run manually otherwise\n",
    "\n",
    "## SLURM PARAMETERS\n",
    "## only edit these parameters if cluster_type == 'slurm'\n",
    "memory = '16GB'\n",
    "wall_time='3:00:00'\n",
    "partition='short'\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'model_path', model_path)\n",
    "progress_paths = update_progress(progress_filepath, 'model_session_path', session_path)\n",
    "progress_paths = update_progress(progress_filepath, 'main_model_path', session_path)\n",
    "\n",
    "learn_model_command(progress_paths, hold_out=hold_out, nfolds=nfolds, num_iter=num_iter, max_states=max_states,\n",
    "                    npcs=npcs, kappa=kappa, separate_trans=separate_trans, robust=robust,\n",
    "                    checkpoint_freq=checkpoint_freq, use_checkpoint=use_checkpoint, select_groups=select_groups,\n",
    "                    cluster_type=cluster_type, min_kappa=min_kappa, scan_scale=scan_scale,\n",
    "                    max_kappa=max_kappa, n_models=n_models, run_cmd=run_cmd, output_dir=modeling_session_path,\n",
    "                    out_script=out_script, memory=memory, wall_time=wall_time, partition=partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best Model Fit\n",
    "Use this feature to determine whether the trained model has captured median syllable durations that match the principal components' changepoints.\n",
    "\n",
    "This feature can also return the best model from a list of models found in the `progress_paths['model_session_path']`.\n",
    "\n",
    "Once completed, the function will update the progress file with the returned model.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to get the best model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_viz.gui import get_best_fit_model\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "\n",
    "output_file = join(progress_paths['plot_path'], 'model_vs_pc_changepoints')\n",
    "\n",
    "best_model_fit = get_best_fit_model(progress_paths, plot_all=True)\n",
    "\n",
    "progress_paths = update_progress(progress_filepath, 'model_path', best_model_fit['best model - duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Notebook End \n",
    "\n",
    "# User Survey\n",
    "\n",
    "Please take some time to tell us your thoughts about this notebook:\n",
    "**[user feedback survey](https://forms.gle/FbtEN8E382y8jF3p6)**"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1623072349278,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.965px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
