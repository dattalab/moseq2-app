{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Project-setup\" data-toc-modified-id=\"Project-setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Project setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Files-and-Directory-Structure\" data-toc-modified-id=\"Files-and-Directory-Structure-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Files and Directory Structure</a></span></li><li><span><a href=\"#Set-up-or-Restore-Progress-Variables\" data-toc-modified-id=\"Set-up-or-Restore-Progress-Variables-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set up or Restore Progress Variables</a></span></li><li><span><a href=\"#Generate-Configuration-Files\" data-toc-modified-id=\"Generate-Configuration-Files-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Generate Configuration Files</a></span></li><li><span><a href=\"#Download-a-Pre-trained-Flip-Classifier-Model-File\" data-toc-modified-id=\"Download-a-Pre-trained-Flip-Classifier-Model-File-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Download a Pre-trained Flip Classifier Model File</a></span></li></ul></li><li><span><a href=\"#Raw-Data-Extraction\" data-toc-modified-id=\"Raw-Data-Extraction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Raw Data Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interactive-Arena-Detection-Tool\" data-toc-modified-id=\"Interactive-Arena-Detection-Tool-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Interactive Arena Detection Tool</a></span></li><li><span><a href=\"#Extract-Session(s)\" data-toc-modified-id=\"Extract-Session(s)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract Session(s)</a></span></li><li><span><a href=\"#[OPTIONAL]-Run-Extraction-Validation-Tests\" data-toc-modified-id=\"[OPTIONAL]-Run-Extraction-Validation-Tests-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>[OPTIONAL] Run Extraction Validation Tests</a></span></li><li><span><a href=\"#[OPTIONAL]-Review-Extraction-Output\" data-toc-modified-id=\"[OPTIONAL]-Review-Extraction-Output-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>[OPTIONAL] Review Extraction Output</a></span></li><li><span><a href=\"#Aggregate-the-Extraction-Results\" data-toc-modified-id=\"Aggregate-the-Extraction-Results-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Aggregate the Extraction Results</a></span></li><li><span><a href=\"#Assign-Groups\" data-toc-modified-id=\"Assign-Groups-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Assign Groups</a></span></li><li><span><a href=\"#[OPTIONAL]-Further-Extraction-Diagnostics\" data-toc-modified-id=\"[OPTIONAL]-Further-Extraction-Diagnostics-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>[OPTIONAL] Further Extraction Diagnostics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Look-Up-Sessions-Using-Their-UUID\" data-toc-modified-id=\"Look-Up-Sessions-Using-Their-UUID-3.7.1\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span>Look Up Sessions Using Their UUID</a></span></li></ul></li></ul></li><li><span><a href=\"#Principal-Component-Analysis-(PCA)\" data-toc-modified-id=\"Principal-Component-Analysis-(PCA)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Principal Component Analysis (PCA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-Principal-Component-Scores\" data-toc-modified-id=\"Computing-Principal-Component-Scores-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Computing Principal Component Scores</a></span></li><li><span><a href=\"#Apply-Pre-trained-AR-HMM\" data-toc-modified-id=\"Apply-Pre-trained-AR-HMM-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Apply Pre-trained AR-HMM</a></span></li></ul></li><li><span><a href=\"#Notebook-End\" data-toc-modified-id=\"Notebook-End-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Notebook End</a></span></li><li><span><a href=\"#User-Survey\" data-toc-modified-id=\"User-Survey-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>User Survey</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1oc0_0mlN0VTZEPMQTg_hnYAC87Lb58MI\">\n",
    "\n",
    "**Welcome to MoSeq2 Apply Pre-trained Model Notebook!**\n",
    "\n",
    "This notebook contains functionalities to apply a pre-trained AR-HMM on a new dataset. Broadly, this notebook is built to:\n",
    "1. extract mice from the newly recorded depth videos\n",
    "2. reduce the dimensionality of the extracted data using the PCA results computed from the dataset orignally used to train the model\n",
    "3. generate syllable labels by applying the model to the new dataset\n",
    "\n",
    "Many of the steps are similar to the [MoSeq2 Extract Modeling Notebook](./MoSeq2-Extract-Modeling-Notebook.ipynb).\n",
    "\n",
    "In this notebook, the **Markdown** above each cell describes the purpose of the cell(s), cell output, and the instructions for running the cell(s) and/or interacting with the widget. The **inline code comments** in the code block provides contextual information about the function, code structure, and parameters.  __The model output can be analyzed using the [MoSeq2 Analysis Visualization Notebook](./MoSeq2-Analysis-Visualization-Notebook.ipynb).__\n",
    "\n",
    "For more detailed documentation, please visit our [Wiki](https://github.com/dattalab/moseq2-app/wiki).\n",
    "For general feedback and feature requests, please fill out [this survey](https://forms.gle/FbtEN8E382y8jF3p6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup\n",
    "\n",
    "## Files and Directory Structure\n",
    "\n",
    "The currently accepted depth data extensions are:\n",
    "- `.dat` (raw depth files from our kinect2 data acquisition software)\n",
    "- `.tar.gz` (compressed depth files from our kinect2 data acquisition software)\n",
    "- `.avi` (compressed depth files from the `moseq2-extract` CLI)\n",
    "\n",
    "Each MoSeq project should be organized within one project directory.\n",
    "To better organize the extraction, modeling, and analysis results, you should copy the MoSeq notebooks to the data directory that contains the depth recording to be analyzed ((i.e. in  `<ds2_dir>` in the directory structure below).)\n",
    "If you're running this notebook from a Docker container, the notebooks should already be copied into your data directory.\n",
    "At this stage, the base directory should contain **separate subfolders** for each depth recording session, as shown below:\n",
    "\n",
    "```\n",
    ".                                ** current working directory\n",
    "└── <ds1_dir>/                   ** directory with the depth recordings used to train the pre-trained model\n",
    "    ├── session_1/               ** - the folder containing data for a single recording session\n",
    "    ...\n",
    "    ├── session_n/\n",
    "    ├── aggregate_results/       ** aggregated extracted data from all sessions in the dataset\n",
    "    ├── _pca/                    ** folder for all the PCA results\n",
    "    ├   ├── pca.h5               ** the learned PC components\n",
    "    ├   ├── pca.yaml             ** the PCA parameters\n",
    "    ├   ├── pca_components.png   ** visualization of the PC components\n",
    "    ├   ├── pca_scree.png        ** visualization of the PC scree plot\n",
    "    ├   └── pca_scores.h5        ** pc score results for the dataset\n",
    "    ├── _models/                 ** folder for all the models trained on the dataset\n",
    "    ├   └── model.p              ** AR-HMM trained on the dataset\n",
    "└── <ds2_dir>/                   ** directory with the depth recordings to apply the pre-trained model on\n",
    "    ├── session_1/\n",
    "    ...\n",
    "    └── session_n/\n",
    "```\n",
    "\n",
    "Using the example directory structure above, this notebook is intended to be used for `<ds2_dir>`, i.e., a newly acquired dataset, to assign syllable labels using the AR-HMM trained on the data from `<ds1_dir>`. \n",
    "\n",
    "You can find more information about the file structure [here](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline).\n",
    "\n",
    "## Set up or Restore Progress Variables\n",
    "\n",
    "**[IMPORTANT] ALWAYS run this cell when you open this notebook.** If you don't, the pipeline won't work properly.\n",
    "\n",
    "MoSeq uses a [progress.yaml file](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#progressyaml) to keep track of your progression through the pipeline. \n",
    "\n",
    "The following cell generates a `progress.yaml` file if there isn't one present.\n",
    "If there is, it loads your progress from the last saved checkpoint (each step in the pipeline saves a checkpoint).\n",
    "It also displays your progress through the pipeline and prints session names that haven't been extracted.\n",
    "\n",
    "**Instructions:**\n",
    "- **Specify the base directory, the folder with all the depth recordings,** in the `base_dir` field. No change is needed if the notebooks are in the base directory.\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import check_progress, restore_progress_vars\n",
    "\n",
    "base_dir = './' # Add the path to your data folder here.\n",
    "progress_filepath = join(base_dir, 'progress.yaml')\n",
    "\n",
    "progress_paths = restore_progress_vars(progress_filepath, init=True, overwrite=False)\n",
    "check_progress(progress_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Configuration Files\n",
    "\n",
    "MoSeq uses a [config.yaml file](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#configyaml) to hold all the configurable parameters for each step in the MoSeq pipeline.\n",
    "Parameters are added to this file as you progress through the notebook.\n",
    "You can copy the config file to another project to run MoSeq with the same parameters as this project.\n",
    "\n",
    "The following cell generates the `config.yaml` file for the analysis pipeline.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import generate_config_command\n",
    "\n",
    "config_filepath = join(progress_paths['base_dir'], 'config.yaml')\n",
    "# specify the specify the camera type\n",
    "camera_type = 'k2' # 'k2' or 'azure'\n",
    "\n",
    "print(f'generating file in path: {config_filepath}')\n",
    "generate_config_command(config_filepath, camera_type=camera_type)\n",
    "progress_paths = update_progress(progress_filepath, 'config_file', config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a Pre-trained Flip Classifier Model File\n",
    "\n",
    "MoSeq2 uses a Random Forest flip classifier to guarantee that the mouse is always pointed to the right after cropping and rotationally aligning mice in the depth videos. The flip classifiers we provide __are trained for experiments run with C57BL/6 mice using Kinect v2 depth cameras__.\n",
    "\n",
    "If your dataset does not work with our pre-trained flip classifiers, we provide a [flip-classifier training notebook](./Flip-Classifier-Training-Notebook.ipynb) to train your own classifier.\n",
    "Instead of running the cell below, add the path of your custom classifier to the `flip_classifier` field in your `config.yaml` file.\n",
    "\n",
    "The following cell downloads a pretrained flip classifier.\n",
    "\n",
    "**Instructions:**\n",
    "- **Select a classifier** that is trained on a dataset that best matches your experiment set up by changing the `selection` parameter in the `download_flip_command` function.\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_extract.gui import download_flip_command\n",
    "# selection=0 - large mice with fibers (K2)\n",
    "# selection=1 (default) - adult male C57s (K2)\n",
    "# selection=2 - mice with Inscopix cables (K2)\n",
    "# selection=3 - adult male C57s (Azure)\n",
    "selection = 1\n",
    "download_flip_command(progress_paths['base_dir'], config_filepath, selection=selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Arena Detection Tool\n",
    "\n",
    "Many parameters are related to detecting the arena floor, which is the region the extraction step should look to find the mouse. Use this interactive tool to optimize parameters before extracting all of your data. This tool can also be used to catch possibly corrupted or inconsistent sessions, and to diagnose arena detection or extraction errors. You can find more detailed information on how to use this widget in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#interactive-arena-detection-tool).\n",
    "\n",
    "Run the following cell to start the interactive widget. After running this tool, a [session-config.yaml file](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#session-configyaml) will be generated, containing session-specific parameters.\n",
    "\n",
    "If the previous steps are run using the Command Line Interface, please run the [Setup or Restore Progress Variables cell](#Set-up-or-Restore-Progress-Variables) to setup/update the `progress.yaml` file to record the progress of the analysis pipeline.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell** to initialize the Arena detection widget. The cell renders a control panel to configure parameters for detecting the arena.\n",
    "- By default, the widget selects the first session in your dataset, sorted alphanumerically.\n",
    "- Adjust the depth range for detecting the floor of the arena.\n",
    "- Adjust the dilation iterations to include more of the wall of the arena.\n",
    "- Click the `Compute arena mask` button to compute and display the mask for the detected floor given the parameters. The displayed mask won't recompute and refresh when you change the parameters unless you click the button.\n",
    "- Check the \"Show advanced arena mask parameters\" checkbox to display more advanced arena mask parameters and you can find more information about the parameters by running the CLI `moseq2-extract extract --help`. You can find documentation for CLI [here](https://github.com/dattalab/moseq2-app/wiki/Command-Line-Interface-for-Extraction-and-Modeling#extract-data).\n",
    "- If you like the arena mask, click the `Compute extraction` button to extract a subset of the data.\n",
    "- Once you are satisfied with the extraction, click the `Save parameters...` button to move on to the next session and save this session's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.util import update_config\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_app.roi.widget import ArenaMaskWidget\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "session_config_path = join(progress_paths['base_dir'], 'session_config.yaml')\n",
    "progress_paths = update_progress(progress_filepath, 'session_config', session_config_path)\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "\n",
    "    config_data['camera_type'] = 'auto' # 'kinect' or 'manual'\n",
    "    config_data['output_dir'] = 'proc' # the subfolder extracted data is saved to\n",
    "\n",
    "    # OPTIONAL additional parameters\n",
    "    # config_data['flip_classifier'] = './alternative-flip-classifier.pkl' # updated flip classifier path\n",
    "\n",
    "# Set to False to show and re-extract extracted recordings\n",
    "skip_extracted = True\n",
    "\n",
    "ArenaMaskWidget(progress_paths['base_dir'], progress_paths['config_file'], progress_paths['session_config'], skip_extracted=skip_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Session(s)\n",
    "The following cell uses the parameters from the [config.yaml](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#configyaml) file or [session-config.yaml](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#session-configyaml) to extract the mouse and scalar values related to mouse movement (velocity, height, position, etc) from the depth videos. You can find the file structure after extracting session(s) [here](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#after-extracting-the-data).\n",
    "\n",
    "This cell takes quite a while to run. Each ~30-minute depth recording can take around 10-15 minutes to extract assuming data is saved in `.dat` format. Each session is extracted serially.\n",
    "\n",
    "If you are on a computing cluster managed with Slurm, [check out our wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#extracting-sessions-in-parallel-with-slurm) to learn about how to run extractions in parallel, rather than serially.\n",
    "\n",
    "**Note:** If sessions are not listed when running the cell, ensure the contents of the `extensions` variable match extension of your depth files.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moseq2_app.util import update_config\n",
    "from moseq2_extract.gui import extract_found_sessions\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    \n",
    "    config_data['cluster_type'] = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
    "\n",
    "    ## SLURM PARAMETERS\n",
    "    # config_data['prefix'] = 'source ~/.bashrc; conda activate moseq2-app; ' # prefix that activates the conda environment\n",
    "    # config_data['memory'] = '6GB'\n",
    "    # config_data['wall_time'] = '1:00:00' # allocated time to run an extraction\n",
    "    # config_data['partition'] = 'short' # slurm partition\n",
    "    # config_data['run_cmd'] = True # if False, extract_out_script must be run manually\n",
    "    # config_data['extract_out_script'] = 'extract_out.sh'\n",
    "\n",
    "# include the file extensions for the depth files you would like to search for and extract.\n",
    "extensions = ['.avi', '.dat', '.tar.gz'] # .avi, .dat, and/or `.tar.gz`\n",
    "\n",
    "# Set to False to select specific recordings to extract\n",
    "extract_all = True\n",
    "\n",
    "# skip_extracted is set in the arena mask widget cell above\n",
    "\n",
    "extract_found_sessions(progress_paths['base_dir'], \n",
    "                       progress_paths['config_file'], \n",
    "                       extensions, \n",
    "                       extract_all=extract_all, \n",
    "                       skip_extracted=skip_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Run Extraction Validation Tests\n",
    "\n",
    "The following few cells allow you to review the extraction quality, as it can affect the model results.\n",
    "The cell below indicates potential outlier sessions relative to the rest of your dataset by looking at the distribution of extracted features averaged over the session. \n",
    "To visually inspect the extraction, use the [Review Extraction Output](#[OPTIONAL]-Review-Extraction-Output) below.\n",
    "To visualize potential anomalies in the extracted features, use the [Further Extraction Diagnostics](#[OPTIONAL]-Further-Extraction-Diagnostics) below.\n",
    "\n",
    "The following cell runs data validation tests on the extracted data, displaying warnings if there are any potential outliers.\n",
    "You can find more information about what the warnings mean in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#run-extraction-validation-tests).\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import validate_extractions\n",
    "\n",
    "validate_extractions(progress_paths['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Review Extraction Output\n",
    "Use the following cell to visually inspect the extractions.\n",
    "You can find examples of a good and a bad extraction [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#examples-of-a-good-extraction-and-a-bad-extraction).\n",
    "\n",
    "**Note:** this cell takes a while (5-10 seconds) to load each video into the notebook, and although it might seem like nothing is happening, the widget is preparing the video\n",
    "Be patient as the data loads. This widget only works in Chrome.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Select a session** from the `Session` dropdown menu to preview its extraction output.\n",
    "- **Change the Playback Speed** slider to speed up or slow down the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import preview_extractions\n",
    "\n",
    "preview_extractions(progress_paths['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the Extraction Results\n",
    "The extraction results are aggregated into a folder called `aggregate_results` to organize the extracted data in a new folder for the rest of the pipeline.\n",
    "\n",
    "The following cell aggregates extraction results into one folder and generates a [moseq2-index.yaml](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#moseq2-indexyaml) file to store all the session-specific information.\n",
    "This step requires that all your sessions have a `metadata.json` file containing a session name for them to be properly aggregated. **Running this cell will generate a new `moseq2-index.yaml` file and overwrite the original one. You will need to reset the group labels and add back the PCA score path at the bottom of the new `moseq2-index.yaml`.**\n",
    "\n",
    "**Instructions:**\n",
    "- **run the following cell**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_extract.gui import aggregate_extract_results_command\n",
    "\n",
    "recording_format = '{start_time}_{session_name}_{subject_name}' # filename formats for the copied extracted data files\n",
    "\n",
    "# directory name to save all metadata + extracted videos to with the format above\n",
    "aggregate_results_dirname = 'aggregate_results/'\n",
    "\n",
    "train_data_dir = join(progress_paths['base_dir'], aggregate_results_dirname)\n",
    "update_progress(progress_filepath, 'train_data_dir', train_data_dir)\n",
    "\n",
    "index_filepath = aggregate_extract_results_command(progress_paths['base_dir'], recording_format, aggregate_results_dirname)\n",
    "progress_paths = update_progress(progress_filepath, 'index_file', index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Groups\n",
    "Sessions can be given group labels for analyses comparing different cohorts or experimental conditions and the labels will be stored in the [moseq2-index.yaml file](https://github.com/dattalab/moseq2-app/wiki/Directory-Structures-and-yaml-Files-in-MoSeq-Pipeline#moseq2-indexyaml). You can find more information about this widget in the [wiki](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#assign-groups).\n",
    "\n",
    "If any of the previous steps are run using the Command Line Interface, please run the [Setup or Restore Progress Variables cell](#Set-up-or-Restore-Progress-Variables) to set up/update the `progress.yaml` file with results run from the CLI.\n",
    "\n",
    "The following cell runs the widget to assign groups and update the `moseq2-index.yaml` file.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Click the column header** to sort the column and use the filter icon to filter if needed.\n",
    "- **Click on the session** to select the session. **To select multiple sessions, click the sessions while holding down the [Ctrl]/[Command] key, or click the first and last entry while holding down the [Shift] key.**\n",
    "- **Enter the group name in the `Desired Group Name` field** and click `Set Group` to update the `group` column for the selected sessions.\n",
    "- Click the `Update Index File` button to save current group assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_group_setting\n",
    "\n",
    "interactive_group_setting(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Further Extraction Diagnostics\n",
    "Using the following tool to visualize the distribution of scalar values can help with discovering possible outlier sessions.\n",
    "\n",
    "If outlier sessions do exist, review the extraction video using the Review Extractions tool and check for any irregularities.\n",
    "You may need to re-extract or discard sessions depending on the issues you catch.\n",
    "You can find more information in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#scalar-summary-for-further-extraction-diagnostics).\n",
    "\n",
    "The following cell starts the interactive widget that visualizes the distribution of average scalar values for each session.\n",
    "\n",
    "**Instructions:**\n",
    "- **Run the following cell**.\n",
    "- **Select a scalar to plot from the window that appears.**\n",
    "- **Hold [CTRL]/[Command] and click on the scalars** to select multiple scalars to plot.\n",
    "- **Hover over the data points** to display the session information.\n",
    "- **Click on the legend items to show/hide groups** from the plot. Double click an item to show a single group.\n",
    "- **Click the camera icon in the toolbar on top of the figures** to save the figures as SVG in your default web image download folder. The toolbar will display when you hover your mouse over the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import interactive_scalar_summary\n",
    "\n",
    "viewer = interactive_scalar_summary(progress_paths['index_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look Up Sessions Using Their UUID\n",
    "Use the widget below to look up additional information about individual sessions, such as where the sessions are located, by using their UUID. \n",
    "You can find more information about this tool in the wiki [here](https://github.com/dattalab/moseq2-app/wiki/MoSeq2-Extract-Modeling-Notebook-Instructions#uuid-lookup).\n",
    "\n",
    "The following cell outputs additional information about the session with the target UUID.\n",
    "\n",
    "**Instructions:**\n",
    "- **Hover over the data point of interest** in the widget above to display Session Name, Subject Name, and UUID.\n",
    "- To look up the file paths associated with the UUID, **input the UUID in the `target_uuid` variable** below, partial UUID is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.util import uuid_lookup\n",
    "\n",
    "# Input full/partial UUID to lookup, eg. 40 is a partial UUID\n",
    "target_uuid = '40'\n",
    "\n",
    "# viewer.sorted_index['files'] is the uuid info dictionary\n",
    "uuid_lookup(target_uuid, viewer.sorted_index['files'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Principal Component Scores\n",
    "To apply the pre-trained AR-HMM to a new dataset, you need to compute the principal component scores for the new dataset using the PCs learned from the dataset the pre-trained AR-HMM was trained on. \n",
    "\n",
    "This step applies the learned PCs to the new extracted depth recordings and produces a 10-dimensional time series of PC scores for each session in your project.\n",
    "\n",
    "**Instructions:**\n",
    "- Verify that the `component_file` variable is set to the file path where the principal components are saved (i.e., `pca.h5`).\n",
    "- **Run the following cell** to compute principal component scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from moseq2_pca.gui import apply_pca_command\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_app.util import update_config\n",
    "\n",
    "# Path to the learned PCA file here\n",
    "component_file = '../ds1_dir/_pca/pca.h5'\n",
    "\n",
    "pca_dirname = './_pca' # Directory to save your computed PC score results\n",
    "progress_paths = update_progress(progress_filepath, 'pca_dirname', pca_dirname) # record the path to save the pc scores\n",
    "\n",
    "scores_filename = 'pca_scores' # name of the scores file to compute and save\n",
    "scores_file = join(progress_paths['pca_dirname'], scores_filename + '.h5') # path to input PC scores file to model\n",
    "progress_paths = update_progress(progress_filepath, 'scores_path', scores_file) # record the path to save the pc scores file\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    # set path to pca.h5\n",
    "    config_data['pca_file'] = component_file\n",
    "\n",
    "apply_pca_command(progress_paths, scores_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Pre-trained AR-HMM\n",
    "\n",
    "This step applies a pre-trained AR-HMM model to the extracted and dimensionally-reduced dataset from above. Applying the AR-HMM on a new dataset means the pre-trained model would generate syllable labels based on applying the learned model parameters on the PC scores of the new dataset. **This process doesn't train a model with the new dataset. The output of this cell is a file with computed syllable labels for the new dataset plus metadata about the applied model, saved in a format readable by the analysis and visualization notebook.**\n",
    "\n",
    "**Instructions:**\n",
    "- Update the path defined in the `pre_trained_model` variable with the pre-trained model path.\n",
    "- Update the `base_model_path` to reflect the folder to save the output model objects.\n",
    "- [OPTIONAL] Specify the file name to save the output model object, default is the same name as the pre-trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "from moseq2_app.gui.progress import update_progress\n",
    "from moseq2_app.util import update_config\n",
    "from moseq2_model.gui import apply_model_command\n",
    "\n",
    "# path to the pre-trained model to apply to the new dataset\n",
    "pre_trained_model = '../ds1_dir/models/model.p'\n",
    "\n",
    "# set the folder to save the output model objects\n",
    "base_model_path = 'applied_models/' \n",
    "\n",
    "# specify the file name to save the computed syllable labels, default is the same name as the pre-trained model\n",
    "dest_model_name = basename(pre_trained_model)\n",
    "\n",
    "# record the path to save the applied model results\n",
    "progress_paths = update_progress(progress_filepath, 'model_path', join(progress_paths['base_dir'], base_model_path, dest_model_name))\n",
    "# record the path to folder for the applied model results \n",
    "progress_paths = update_progress(progress_filepath, 'base_model_path', join(progress_paths['base_dir'], base_model_path))\n",
    "\n",
    "with update_config(progress_paths['config_file']) as config_data:\n",
    "    # Variable name in input file with PCs\n",
    "    config_data['var_name'] = 'scores'\n",
    "    config_data['load_groups'] = True\n",
    "\n",
    "apply_model_command(progress_paths, pre_trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Notebook End \n",
    "\n",
    "# User Survey\n",
    "\n",
    "Please take some time to tell us your thoughts about this notebook:\n",
    "**[user feedback survey](https://forms.gle/S88jptAEs41mQjff7)**"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1623072349278,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.965px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "82eecf3e690e1a91ab50e0913e9887c9714287148abb8904ea9640df75dffa19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
