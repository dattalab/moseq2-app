{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "303.993px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Handsfree-MoSeq2-Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH0LL0mvjq_b"
      },
      "source": [
        "***\n",
        "<center><h1>Handsfree MoSeq2 App</h1></center>\n",
        "\n",
        "***\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1kHdmkBx_XlueTJocREDx4YeHGrjfYKJv\">\n",
        "\n",
        "This notebook assumes you're familiar with \"Main-MoSeq2-Notebook\" and are looking for your code to run a bit more autonomously. Here, we remove most of the interactivity of the Main-MoSeq2-Notebook, so that you can run extraction, dimensionality reduction, and modeling sequentially without any user intervention. This is great if you're processing a large cohort or are analyzing a new cohort with parameters similar to a previous one. \n",
        "\n",
        "This notebook **assumes** that you've already optimized your moseq parameters in Main-MoSeq2-Notebook. As you work through this notebook, you'll have clear opportunities to **copy your parameters into their appropriate places.** \n",
        "\n",
        "Once you've done this, the next section will all you to conveniently just run **\"Run All Below\"** at which point you can step away from the computer and go do some experiments, make dinner, run you errands, or (as we often do) sleep.\n",
        "\n",
        "When the MoSeq computations are complete, you're welcome to **create a new copy of \"Main-MoSeq2-Notebook\" in the same directory as this** and restore progress variables inside that notebook. You can then create any of the intermediate plots that you'd like to see (heatmaps, pca variance, etc.). You can also just move from this handsfree notebook to the interactive results notebook to start visualizing your results there. \n",
        "\n",
        "***\n",
        "\n",
        "##### Notebook Shortcuts\n",
        "- **[Notebook Setup](#Notebook-Setup)**: Prepare all the necessary config and progress files\n",
        "- **[Set Parameters for All MoSeq Steps](#Set-Parameters-for-All-MoSeq-Steps)**: Set the parameters for everything\n",
        "- **[Run All MoSeq Steps](#Run-All-MoSeq-Steps)**: Run the code for all the important MoSeq Steps\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0qfzMSlJA8"
      },
      "source": [
        "### Setting up the environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRk6g-5S5uAS"
      },
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/');\n",
        "\n",
        "# Colab use TensorFlow 2 by default\n",
        "# MoSeq uses Numpy 1.18 so this line changes the TensorFlow version to 1.x to support a lower version of Numpy\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Change to the proper working directory\n",
        "%cd /content/drive/MyDrive/MoSeq\n",
        "\n",
        "# Restart runtime after this cell is run and run this cell again\n",
        "%cd moseq2-extract\n",
        "!git checkout dev\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "%cd moseq2-model\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "%cd moseq2-viz\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "%cd moseq2-pca\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "%cd moseq2-app\n",
        "! git checkout google_colab\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "!pip install -U kora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdS_qCCDwGyQ"
      },
      "source": [
        "!moseq2-extract --version\n",
        "!moseq2-pca --version\n",
        "!moseq2-model --version\n",
        "!moseq2-viz --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NCquChRjq_d"
      },
      "source": [
        "***\n",
        "<center><h1>Notebook Setup</h1></center>\n",
        "\n",
        "***\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Zkd0tATi8r2ENHvN8OczIrEf4K8PFmhM\">\n",
        "\n",
        "### Check if the dependencies are found\n",
        "\n",
        "Run the following cell to check if `moseq2-app` is installed in your current conda kernel. The latest working version number is `0.2.1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inyQAwk_jq_d"
      },
      "source": [
        "import moseq2_app\n",
        "print(moseq2_app.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoAjcTYwjq_e"
      },
      "source": [
        "## Create/Restore The Progress File and Check Current Progress\n",
        "\n",
        "- Use this cell to find and load your current notebook analysis progress. You will want to use your current directory, AKA `./`, in order for all of the media to be displayed properly.\n",
        "- __Ensure the directory this notebook is launched from contains all the experimental session folders.__\n",
        "\n",
        "The cell will print progress bars for each pipeline step in the notebook. \n",
        "- The extraction progress bar indicates total the number of extracted sessions detected in the provided `base_dir` path. Additionally the names of the sessions that are yet to be extracted will be printed for your convenience. __Note: the progress does not reflect the contents of the aggregate_results/ folder.__\n",
        "- The remainder of the progress bars are derived from reading the paths in the `progress_paths` dict, filling up the bar if the included paths are found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHuknWYowRpF"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EITe6FTCjq_e"
      },
      "source": [
        "from os.path import join\n",
        "from moseq2_app.gui.progress import check_progress, restore_progress_vars\n",
        "\n",
        "# Add the path to your data folder here.\n",
        "# We recommend that you run this notebook in the same folder as your data. In that case, you don't have to change base_dir\n",
        "base_dir = './example_data'\n",
        "progress_filepath = join(base_dir, 'progress.yaml')\n",
        "\n",
        "progress_paths = restore_progress_vars(progress_filepath, init=True, overwrite=False)\n",
        "check_progress(progress_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2MEbdJ3jq_f"
      },
      "source": [
        "### Generate Configuration Files\n",
        "\n",
        "The `config.yaml` will be used to hold all configurable parameters for all steps in the MoSeq pipeline. The parameters used will be added to this file as you progress through the notebook. You can then use it to run an identical pipeline in future analyses, or directly configure parameters from there when debugging cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYhE0iU8jq_f"
      },
      "source": [
        "from os.path import join\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "from moseq2_extract.gui import generate_config_command\n",
        "\n",
        "config_filepath = join(progress_paths['base_dir'], 'config.yaml')\n",
        "\n",
        "print(f'generating file in path: {config_filepath}')\n",
        "generate_config_command(config_filepath)\n",
        "progress_paths = update_progress(progress_filepath, 'config_file', config_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvbgSfVTjq_f"
      },
      "source": [
        "### Download a Flip File\n",
        "\n",
        "MoSeq2 currently uses a deep-learning flip classifier to guarantee that the mouse is always oriented facing east (post-extraction). The flip-classifier currently __best suits mice that are similar to adult male c57 mice recorded with Kinect v2 cameras__.\n",
        "\n",
        "If your dataset does not work with these flip classifiers, consider training your own. Click [this link](https://github.com/dattalab/moseq2-app/tree/jupyter/) to view the flip-classifier training notebooks. Once you have it trained, simply add the path to the `config.yaml` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvmljedhjq_g"
      },
      "source": [
        "from moseq2_extract.gui import download_flip_command\n",
        "# selection=0 - large mice with fibers (default)\n",
        "# selection=1 - adult male C57s\n",
        "# selection=2 - mice with Inscopix cables\n",
        "download_flip_command(progress_paths['base_dir'], config_filepath, selection=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qXvriXCjq_g"
      },
      "source": [
        "***\n",
        "<center><h1>Set Parameters for All MoSeq Steps</h1></center>\n",
        "\n",
        "***\n",
        "\n",
        "## Extraction Parameters\n",
        "Set these based on experience in previous interactive sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kjYF5zHjq_h"
      },
      "source": [
        "from os.path import join\n",
        "import ruamel.yaml as yaml\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "\n",
        "session_config_path = join(progress_paths['base_dir'], 'session_config.yaml')\n",
        "progress_paths = update_progress(progress_filepath, 'session_config', session_config_path)\n",
        "\n",
        "with open(progress_paths['config_file'], 'r') as f:\n",
        "    config_data = yaml.safe_load(f)\n",
        "\n",
        "config_data['camera_type'] = 'kinect' # 'kinect', 'azure' or 'realsense'\n",
        "config_data['crop_size'] = (80, 80)\n",
        "\n",
        "# if using azure or realsense, increase the noise_tolerance\n",
        "config_data['noise_tolerance'] = 30\n",
        "\n",
        "# include the file extensions for the depth files you would like to search for and extract.\n",
        "extensions = ['.avi'] # and/or .dat, .mkv\n",
        "\n",
        "with open(progress_paths['config_file'], 'w') as f:\n",
        "    yaml.safe_dump(config_data, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rqQag1Cjq_h"
      },
      "source": [
        "## Group Assignment Parameters\n",
        "This is an oversimplified version of the group assignment module in the interactive version. \n",
        "\n",
        "This assumes that your file naming has some structure to it that will allow us to identify the necessary groups. For example, if you're comparing mice administered saline and amphetamine, some consistent tag should distinguish these mice in the data folder names, like \"sal\" and \"amp.\" Luckily, this is flexible enough to handle many groups, so it is not just limited to two!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13L_0y9Djq_h"
      },
      "source": [
        "# value-group lookup parameters\n",
        "by = 'SessionName' # or SubjectName\n",
        "value = ['saline_', 'amphetamine_'] # value of the corresponding key; can be string or list\n",
        "group = ['Saline', 'Amphetamine'] # designated group name; can be string or corresponding list\n",
        "\n",
        "# filtering parameters\n",
        "exact = False # Must be exact value-group match(es)\n",
        "lowercase = False # look for values after applying lowercase to them\n",
        "negative = False # select opposite selection than value-group pair(s) given"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNNTxplUjq_h"
      },
      "source": [
        "## PCA Parameters\n",
        "Similar to before, set these based on experience.\n",
        "\n",
        "Make sure to add the necessary dask parameters if you're using dask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmUcGthrjq_i"
      },
      "source": [
        "from os.path import join\n",
        "import ruamel.yaml as yaml\n",
        "from moseq2_pca.gui import train_pca_command\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "\n",
        "with open(progress_paths['config_file'], 'r') as f:\n",
        "    config_data = yaml.safe_load(f)\n",
        "\n",
        "# PCA parameters you may need to configure\n",
        "config_data['overwrite_pca_train'] = True # THIS ALLOWS THIS TO RUN WITHOUT INTERACTION \n",
        "config_data['overwrite_pca_apply'] = True # THIS ALLOWS THIS TO RUN WITHOUT INTERACTION \n",
        "config_data['gaussfilter_space'] = (1.5, 1) # Spatial filter for data (Gaussian)\n",
        "config_data['medfilter_space'] = [0] # Median spatial filter\n",
        "config_data['medfilter_time'] = [0] # Median temporal filter\n",
        "\n",
        "# If dataset includes head-attached cables, set missing_data=True\n",
        "config_data['missing_data'] = False # Set True for dataset with missing/dropped frames to reconstruct respective PCs.\n",
        "config_data['missing_data_iters'] = 10 # Number of times to iterate over missing data during PCA\n",
        "config_data['recon_pcs'] = 10 # Number of PCs to use for missing data reconstruction\n",
        "\n",
        "# Dask Configuration\n",
        "config_data['dask_port'] = '8787' # port to access Dask Dashboard\n",
        "\n",
        "# Changepoint computation parameters you may want to configure\n",
        "config_data['threshold'] = 0.5 # Peak threshold to use for changepoints\n",
        "config_data['dims'] = 300 # Number of random projections to compare the computed principal components with\n",
        "\n",
        "with open(progress_paths['config_file'], 'w') as f:\n",
        "    yaml.safe_dump(config_data, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXThaeehjq_i"
      },
      "source": [
        "## ARHMM Modeling Parameters\n",
        "\n",
        "Set these based on experience and prior tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdy4dVdljq_i"
      },
      "source": [
        "select_groups = False # select specific groups to model; if False, will model all data as is in moseq2-index.yaml\n",
        "\n",
        "# model saving freqency (in interations); will create a checkpoints/ directory containing checkpointed models\n",
        "checkpoint_freq = -1\n",
        "use_checkpoint = False # resume training from latest saved checkpoint\n",
        "\n",
        "# Advanced modeling parameters\n",
        "hold_out = False # boolean to hold out data subset during the training process\n",
        "nfolds = 2 # (if hold_out==True): number of folds to hold out during training; 1 fold per session\n",
        "\n",
        "npcs = 10  # number of PCs being used\n",
        "max_states = 100 # number of maximum states the ARHMM can end up with\n",
        "\n",
        "# use robust-ARHMM with t-distribution -> yields less states/syllables if True, \n",
        "# used to constrict accepted behavioral variability\n",
        "robust = True \n",
        "\n",
        "# separate group transition graphs; set to True if ngroups > 1\n",
        "separate_trans = True \n",
        "\n",
        "num_iter = 100 # number of iterations to train model\n",
        "\n",
        "# syllable length probability distribution prior; (None, int or 'scan'); if None, kappa=nframes\n",
        "kappa = None \n",
        "\n",
        "# if kappa == 'scan', optionally set bounds to scan kappa values between, in either a linear or log-scale.\n",
        "scan_scale = 'log' # or linear\n",
        "min_kappa = None\n",
        "max_kappa = None\n",
        "\n",
        "# total number of models to spool\n",
        "n_models = 5\n",
        "\n",
        "# Select platform to run models on\n",
        "cluster_type = 'local' # currently supported cluster_types = 'local' or 'slurm'\n",
        "run_cmd = False # if True, runs the commands via os.system(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThAMgrHzjq_i"
      },
      "source": [
        "***\n",
        "<center><h1>Run All MoSeq Steps</h1></center>\n",
        "\n",
        "***\n",
        "\n",
        "This section is intentionally designed for you to be able to now just run **\"Run All Below\"** The rest of the notebook will then run all the important MoSeq Steps and save them in their appropriate places. \n",
        "\n",
        "If you wish to visualize any of the steps, you can **open up a new copy of \"Main-MoSeq2-Notebook\"**, restore progress variables, and then run any of the visualization steps that you so wish.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3lMPNQejq_j"
      },
      "source": [
        "### (Convenience Cell) Restore Progress Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM4HtK3AzE5X"
      },
      "source": [
        "base_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfgc3wRMjq_j"
      },
      "source": [
        "from moseq2_app.gui.progress import restore_progress_vars\n",
        "import os\n",
        "\n",
        "progress_filepath = os.path.join(base_dir, 'progress.yaml')\n",
        "print(progress_filepath)\n",
        "\n",
        "progress_paths = restore_progress_vars(progress_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1krUJLRzjq_j"
      },
      "source": [
        "## Run Extraction and Validation\n",
        "\n",
        "- Keep `extract_all=True` to prevent interactivity\n",
        "- If `skip_extracted=True`, the command will only search for (and list) sessions that have not been previously extracted.\n",
        "\n",
        "__Note: If sessions are not listed when running the cell, ensure your selected extension matches that of your depth files.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mmXiTUOdjq_j"
      },
      "source": [
        "from moseq2_extract.gui import extract_found_sessions\n",
        "from moseq2_app.main import validate_extractions\n",
        "\n",
        "extract_found_sessions(progress_paths['base_dir'], progress_paths['config_file'], extensions, extract_all=True, skip_extracted=True)\n",
        "validate_extractions(progress_paths['base_dir'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSv4NYmjq_k"
      },
      "source": [
        "### Aggregate your results into one folder and generate an index file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZciR-Zhgjq_k"
      },
      "source": [
        "from os.path import join\n",
        "from moseq2_extract.gui import aggregate_extract_results_command\n",
        "\n",
        "recording_format = '{start_time}_{session_name}_{subject_name}' # filename formats for the copied extracted data files\n",
        "\n",
        "# directory NAME to save all metadata+extracted videos to with above respective name format\n",
        "aggregate_results_dirname = 'aggregate_results/'\n",
        "\n",
        "train_data_dir = join(progress_paths['base_dir'], aggregate_results_dirname)\n",
        "update_progress(progress_filepath, 'train_data_dir', train_data_dir)\n",
        "\n",
        "# the subpath indicates to only aggregate extracted session paths with that subpath, only change if aggregating data from a different location\n",
        "index_filepath = aggregate_extract_results_command(progress_paths['base_dir'], recording_format, aggregate_results_dirname)\n",
        "progress_paths = update_progress(progress_filepath, 'index_file', index_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvqK4a4Bjq_k"
      },
      "source": [
        "### Run Group Setting\n",
        "This will set the groups based on key terms in the folder names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFlr0NOsjq_k"
      },
      "source": [
        "from moseq2_viz.gui import add_group\n",
        "\n",
        "add_group(progress_paths['index_file'], by=by, value=value, group=group, exact=exact, lowercase=lowercase, negative=negative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYaf-mtnjq_k"
      },
      "source": [
        "## Run PCA Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZmt8JIijq_k"
      },
      "source": [
        "from os.path import join\n",
        "import ruamel.yaml as yaml\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "from moseq2_pca.gui import train_pca_command, apply_pca_command\n",
        "\n",
        "pca_filename = 'pca' # Name of your PCA model h5 file to be saved\n",
        "pca_dirname = '_pca/' # Directory to save your computed PCA results\n",
        "progress_paths = update_progress(progress_filepath, 'pca_dirname', join(progress_paths['base_dir'], pca_dirname))\n",
        "\n",
        "# Train the PCA\n",
        "train_pca_command(progress_paths, pca_dirname, pca_filename)\n",
        "\n",
        "scores_filename = 'pca_scores' # name of the scores file to compute and save\n",
        "scores_file = join(progress_paths['pca_dirname'], scores_filename+'.h5') # path to input PC scores file to model\n",
        "progress_paths = update_progress(progress_filepath, 'scores_path', scores_file)\n",
        "\n",
        "# Apply the PCA\n",
        "apply_pca_command(progress_paths, scores_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQxSmh0Jjq_l"
      },
      "source": [
        "### Run Changepoint Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6cIuiyfjq_l"
      },
      "source": [
        "import ruamel.yaml as yaml\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "from moseq2_pca.gui import compute_changepoints_command\n",
        "\n",
        "changepoints_filename = 'changepoints' # name of the changepoints images to generate\n",
        "progress_paths = update_progress(progress_filepath, 'changepoints_path', changepoints_filename)\n",
        "\n",
        "compute_changepoints_command(progress_paths['train_data_dir'], progress_paths, changepoints_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceHQm2Gjq_l"
      },
      "source": [
        "## Run ARHMM Modeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldo4rtBOjq_l"
      },
      "source": [
        "from os.path import join\n",
        "import ruamel.yaml as yaml\n",
        "from moseq2_model.gui import learn_model_command\n",
        "from moseq2_app.gui.progress import update_progress\n",
        "\n",
        "modeling_session_path = 'model-data/'\n",
        "model_name = 'model.p'\n",
        "session_path = join(progress_paths['base_dir'], modeling_session_path)\n",
        "model_path = join(session_path, model_name) # path to save trained model\n",
        "progress_paths = update_progress(progress_filepath, 'model_path', model_path)\n",
        "progress_paths = update_progress(progress_filepath, 'model_session_path', session_path)\n",
        "\n",
        "learn_model_command(progress_paths, hold_out=hold_out, nfolds=nfolds, num_iter=num_iter, max_states=max_states,\n",
        "                    npcs=npcs, kappa=kappa, separate_trans=separate_trans, robust=robust,\n",
        "                    checkpoint_freq=checkpoint_freq, use_checkpoint=use_checkpoint, select_groups=select_groups,\n",
        "                    cluster_type=cluster_type, min_kappa=min_kappa, scan_scale=scan_scale,\n",
        "                    max_kappa=max_kappa, n_models=n_models, run_cmd=run_cmd, output_dir=modeling_session_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}