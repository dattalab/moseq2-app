{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Label-Correctly-Oriented-Frame-Ranges\" data-toc-modified-id=\"Label-Correctly-Oriented-Frame-Ranges-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Label Correctly Oriented Frame Ranges</a></span><ul class=\"toc-item\"><li><span><a href=\"#Widget-Guide\" data-toc-modified-id=\"Widget-Guide-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Widget Guide</a></span></li><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Instructions</a></span></li></ul></li><li><span><a href=\"#Prepare-Train-Test-Datasets\" data-toc-modified-id=\"Prepare-Train-Test-Datasets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare Train-Test Datasets</a></span></li><li><span><a href=\"#Fit-and-Evaluate-the-Flip-Classifier-Model\" data-toc-modified-id=\"Fit-and-Evaluate-the-Flip-Classifier-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fit and Evaluate the Flip Classifier Model</a></span></li><li><span><a href=\"#Correct-Extracted-Dataset-Using-Train-Flip-Classifer-Model\" data-toc-modified-id=\"Correct-Extracted-Dataset-Using-Train-Flip-Classifer-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Correct Extracted Dataset Using Train Flip Classifer Model</a></span></li><li><span><a href=\"#Preview-Corrected-Sessions\" data-toc-modified-id=\"Preview-Corrected-Sessions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preview Corrected Sessions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Flip Classifier Training Notebook</h1></center>\n",
    "\n",
    "Flip classifiers are RandomForestClassifier models that MoSeq2-Extract uses to ensure that the mouse is always extracted with the mouse's nose pointing to the right and tail to the left. This notebook is a streamlined utility and guide for preparing data and training a model that handles your specific data acquisition use case.\n",
    "\n",
    "To use this notebook, you must first extract some data using MoSeq2-Extract to use as training data for the flip classifier model. 100K frames is optimal for training the flip classifier. \n",
    "\n",
    "This can be an iterative process if your data contains large amounts of flips throughout the extractions. On your first iteration, it is acceptable to extract the data without a flip-classifier. After training a new flip classifier, you may apply it to your dataset to correct the flips without having to re-extract the data before going into the PCA step.\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1cOwyen2Siy-_wJ1HcE0PmMUi3Lcgcwwa\"></center>\n",
    "\n",
    "## Label Correctly Oriented Frame Ranges\n",
    "\n",
    "Use this interactive tool to build your training dataset for the flip classifier model. Select a range of frames and indentify whether the rodent is facing left or facing right. The range of frames are used to build your training set.\n",
    "\n",
    "### Instructions\n",
    "1. Specify the the path to the input data folder in `input_dir`, and the path to the resulting flip classifier model.\n",
    "2. Spedify the maximum number of frames to use** in the `max_frames` field, the default value is 1e5.\n",
    "3. Spedify the number of tail filter iterations** in the `tail_filter_iters` field, the default value is 1.\n",
    "4. Spedify the size of the spatial median blur filter kernel size** in the `space_filter_size` field, the default value is 3.\n",
    "5. Select a sesseion from the dropdown menu.\n",
    "6. Drag the slider to select a frame index to preview, or enter the frame number in the indicator located on the RHS of the frame slider.\n",
    "7. Click `Start Range` to starting selecting the range. Drag the slider to the end of the range. Click `Facing Left` (when the rodent's head is facing left) or `Facing Right` (when the rodent's head is facing right) to specify the correct oriention for the range of frames. After specifying the orientation, the selected frames will be added to the datset used to train the model.\n",
    "8. Click `Cancel Select` to cancel the selection if you are not satified with the selection.\n",
    "The `Current Total Selected` section turns green when there are enough labled frames to train the model.\n",
    "\n",
    "__Note__: If two frame ranges are selected with overlapping frames, the training set will only include the unique selected indices, removing duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from moseq2_app.main import flip_classifier_tool\n",
    "\n",
    "input_dir = './' # Specify the data folder\n",
    "model_path = './flip-classifier-xx-1.pkl' ## e.g. ./flip-classifier-azure-ephys.pkl\n",
    "\n",
    "max_frames = 1e5 # max number of frames to use (performance anecdotally saturates around 1e5)\n",
    "tail_filter_iters = 1 # number of tail filter iterations\n",
    "space_filter_size = 3 # size of the spatial median blur filter kernel size\n",
    "\n",
    "continuous_slider_update = True # update the view as the slider values are updated\n",
    "launch_gui = True # launches the frame selector gui\n",
    "\n",
    "FF = flip_classifier_tool(input_dir=input_dir,\n",
    "                          output_file=model_path,\n",
    "                          max_frames=max_frames,\n",
    "                          tail_filter_iters=tail_filter_iters,\n",
    "                          space_filter_size=space_filter_size,\n",
    "                          continuous_slider_update=continuous_slider_update,\n",
    "                          launch_gui=launch_gui)\n",
    "FF.interactive_launch_frame_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if your frame selection was interrupted for any reason, and you would like to relaunch the tool with all of your previously selected frame ranges, uncomment the code in the following cell and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FF.interactive_launch_frame_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train-Test Datasets\n",
    "\n",
    "This cell splits your dataset into train/validation sets and displays images in the datasets. Upon completion, the cell will plot a 2x2 grid. \n",
    "\n",
    "The left column contains the correctly flipped examples of the data. The right column contains the incorrect examples. The bottom row contains the y-axis flip versions of the top row.\n",
    "\n",
    "**Note:** Ensure that only the plotted frames in the __left__ column show the rodent's nose is pointing to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 20 # percent train/validation split\n",
    "\n",
    "FF.prepare_datasets(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate the Flip Classifier Model\n",
    "The following cell train a random forest classifier model with the data, determine the flip classifier's accuracy, and then save the model to your desired output path.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Specify the maximum depth of the tree, the default value is 6. Increase this value if your data includes larger amounts of variability and you want to increase model complexity. Variability can arise from obstructions, different rodent sizes, larger crop sizes, etc. **Please be mindful of over-fitting**.\n",
    "2. Specify the number of parallel jobs to run `fit()` and `predict()`, the default value is 4.\n",
    "3. Set the `train` variable to `True` if you want to train a new model with the selected data, otherwise it will only evaluate the model on the selected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6 \n",
    "         \n",
    "n_jobs = 4\n",
    "verbose = 0 # levels of verbosity: [0, 1, 2]\n",
    "train = True\n",
    "\n",
    "FF.train_and_evaluate_model(n_jobs=n_jobs,\n",
    "                            max_depth=max_depth,\n",
    "                            verbose=verbose,\n",
    "                            train=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Extracted Dataset Using Train Flip Classifer Model\n",
    "\n",
    "Use a pre-trained flip classifier model to correct extractions in your dataset that may have frames where the rodent is incorrectly flipped. \n",
    "### Instructions\n",
    "1. Specify the path in `frame_path` where frames are found in the h5 files, the default value is `'frames'`.\n",
    "2. Set `write_movie` to `True` if you want to write new movies with the corrected frames.\n",
    "3. Set `Verbose` to `True` if you want to display progress bars for each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 4000\n",
    "frame_path = 'frames'\n",
    "write_movie = True\n",
    "verbose = False\n",
    "\n",
    "FF.apply_flip_classifier(chunk_size=chunk_size,\n",
    "                         frame_path=frame_path,\n",
    "                         write_movie=write_movie,\n",
    "                         verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Corrected Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moseq2_app.main import preview_extractions\n",
    "\n",
    "preview_extractions(input_dir, flipped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
